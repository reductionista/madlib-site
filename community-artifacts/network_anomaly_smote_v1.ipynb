{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network anomaly detection\n",
    "* <a href=\"#tag\">Tag</a>\n",
    "\n",
    "Using network data build a multiclass classification model to predict anomolies\n",
    "\n",
    "- Jan 2021\n",
    "- Domino Valdano and Frank McQuillan\n",
    "\n",
    "\n",
    "## Index\n",
    "\n",
    "### Setup \n",
    "\n",
    "* <a href=\"#dependencies\">Dependencies</a>\n",
    "* <a href=\"#package_options\">Package Options</a>\n",
    "* <a href=\"#database_connection\">Database Connection</a>\n",
    "    \n",
    "    \n",
    "### Data Loading\n",
    "\n",
    "* <a href=\"#external_table\">External Table Definition</a>\n",
    "* <a href=\"#download_data\">Download Data and View Sample</a>\n",
    "\n",
    "\n",
    "### Data Audit\n",
    "\n",
    "* <a href=\"#summary_statistics\">Summary Statistics</a>\n",
    "\n",
    "\n",
    "### Data Exploration\n",
    "\n",
    "* <a href=\"#de_categorical\">Categorical Columns</a>\n",
    "* <a href=\"#de_continuous\">Continuous Columns</a>\n",
    "\n",
    "\n",
    "### Feature Engineering\n",
    "\n",
    "* <a href=\"#fe_continuous\">Continuous Features</a>\n",
    "* <a href=\"#fe_one_hot\">One Hot Encode Categorical Features</a>\n",
    "* <a href=\"#fe_combine\">Combine Continuous & Categorical Features</a>\n",
    "* <a href=\"#fe_cats_dep\">Plot Categorical Features By Response</a>\n",
    "* <a href=\"#fe_chi_sq\">Chi-squared Testing</a>\n",
    "* <a href=\"#fe_corr\">Correlation Testing</a>\n",
    "* <a href=\"#fe_scatter\">Scatter Plots</a>\n",
    "\n",
    "\n",
    "### Model Development\n",
    "\n",
    "* <a href=\"#train_vali_split\">Training & Validation Sample Split</a>\n",
    "\n",
    "\n",
    "* **Random Forest (MADlib)**\n",
    "    * <a href=\"#rf_train_model\">Train model</a>\n",
    "    * <a href=\"#rf_variable_importance\">Variable Importance</a>\n",
    "    * <a href=\"#rf_score_out_of_sample\">Score Validation Data</a>\n",
    "    * <a href=\"#rf_auc\">Area Under ROC Curve</a>\n",
    "    * <a href=\"#rf_roc\">Receiver Operating Characteristic Graph (ROC Curve)</a>\n",
    "    * <a href=\"#rf_confusion_matrix\">Confusion Matrix</a>\n",
    "    * <a href=\"#rf_model_storage\">Model Storage</a>\n",
    "\n",
    "### Model Scoring\n",
    "\n",
    "\n",
    "* <a href=\"#model_scoring_Example\">Model Scoring Example</a>\n",
    "\n",
    "----\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"dependencies\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Greenplum Database 5.x on GCP (PM demo machine) - via tunnel\n",
    "%sql postgresql://gpadmin@localhost:8000/madlib\n",
    "        \n",
    "# PostgreSQL local\n",
    "#%sql postgresql://fmcquillan@localhost:5432/madlib\n",
    "%config SqlMagic.autopandas=True\n",
    "%config SqlMagic.short_errors=False\n",
    "#%config SqlMagic.column_local_vars=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dependencies\n",
    "import psycopg2               # Python-PostgreSQL Database Adapter - https://pypi.python.org/pypi/psycopg2\n",
    "import pandas as pd           # Python Data Analysis Library - https://pandas.pydata.org/\n",
    "import seaborn as sns         # Statistical data visualization - https://seaborn.pydata.org/\n",
    "import math                   # Mathematical functions - https://docs.python.org/2/library/math.html\n",
    "import textwrap as tw         # Text wrapping and filling - https://docs.python.org/2/library/textwrap.html\n",
    "import ipywidgets as widgets  # Jupyter Widgets - https://ipywidgets.readthedocs.io/en/latest/\n",
    "import IPython.display as ipd # http://ipython.org/documentation.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"package_options\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "# package options\n",
    "# %matplotlib inline\n",
    "%pylab inline\n",
    "\n",
    "pylab.rcParams['figure.figsize'] = (12, 8)\n",
    "    \n",
    "pd.options.mode.chained_assignment = None \n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "\n",
    "pd.options.display.max_rows = 10000\n",
    "pd.options.display.max_columns = 10000\n",
    "\n",
    "sns.set(style=\"darkgrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"database_connection\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### Connection Details \n",
       " ------"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Host:**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "edab9d98ef6f46578324a759604a1e90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value=u'')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Port:**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28472c0e9a4d4453af3e0b3d557c53fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value=u'')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Database Name:**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7749461fd5c24494a6f441939493ee2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value=u'')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Username:**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f8dac3487ae4c6db7b3a7f6785745d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value=u'')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Password:**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c07f6e76b31949e987fa233d185dee71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value=u'')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "*Leave blank for default values*"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc65501d2f1e422194c0f8b729fa630d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description=u'Connect', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# init to default values\n",
    "database_host = 'localhost'\n",
    "database_databasename = 'madlib'\n",
    "database_username = 'gpadmin'\n",
    "database_password = ''\n",
    "database_port = '8000'\n",
    "\n",
    "# interpret string as markdown\n",
    "def printmd(string):\n",
    "    ipd.display(ipd.Markdown(string))\n",
    "    \n",
    "# forms\n",
    "message = \"### Connection Details \\n ------\"\n",
    "printmd(message)\n",
    "    \n",
    "printmd(\"**Host:**\")\n",
    "inputHost = widgets.Text()\n",
    "ipd.display(inputHost)\n",
    "\n",
    "printmd(\"**Port:**\")\n",
    "inputPort = widgets.Text()\n",
    "ipd.display(inputPort)\n",
    "\n",
    "printmd(\"**Database Name:**\")\n",
    "inputDatabaseName = widgets.Text()\n",
    "ipd.display(inputDatabaseName)\n",
    "\n",
    "printmd(\"**Username:**\")\n",
    "inputUsername = widgets.Text()\n",
    "ipd.display(inputUsername)\n",
    "\n",
    "printmd(\"**Password:**\")\n",
    "inputPassword = widgets.Text()\n",
    "ipd.display(inputPassword)\n",
    "\n",
    "printmd(\"*Leave blank for default values*\")\n",
    "\n",
    "\n",
    "def db_connect():\n",
    "    global conn, cur\n",
    "    try:\n",
    "        connString = \"host='{}' dbname='{}' user='{}' password='{}' port={}\".format(database_host,database_databasename,database_username,database_password,database_port)\n",
    "        # print connString\n",
    "        conn = psycopg2.connect(connString)\n",
    "        cur = conn.cursor()\n",
    "        conn.autocommit = True\n",
    "        message = \"<span style='color:green'>**Connection successful!**</span>\"\n",
    "        printmd(message)\n",
    "    except:\n",
    "        message = \"<span style='color:red'>**ERROR: Unable to connect to the database**</span>\"\n",
    "        printmd(message)\n",
    "    \n",
    "def on_button_click(b):\n",
    "    \n",
    "    global database_host, database_databasename, database_username, database_password, database_port\n",
    "    \n",
    "    ipd.clear_output()\n",
    "    \n",
    "    message = \"### Connection Details \\n ------\"\n",
    "    printmd(message)\n",
    "    \n",
    "    if inputHost.value == \"\":\n",
    "        message = \"**Host:** {} (default)\".format(database_host)\n",
    "        printmd(message)\n",
    "    else:\n",
    "        database_host = inputHost.value\n",
    "        message = \"**Host:** {}\".format(database_host)\n",
    "        printmd(message)\n",
    "\n",
    "    if inputPort.value == \"\":\n",
    "        message = \"**Port:** {} (default)\".format(database_port)\n",
    "        printmd(message)\n",
    "    else:\n",
    "        database_port = inputPort.value\n",
    "        message = \"**Port:** {}\".format(database_port)\n",
    "        printmd(message)\n",
    "        \n",
    "    if inputDatabaseName.value == \"\":\n",
    "        message = \"**Database name:** {} (default)\".format(database_databasename)\n",
    "        printmd(message)\n",
    "    else:\n",
    "        database_databasename = inputDatabaseName.value\n",
    "        message = \"**Database name:** {}\".format(database_databasename)\n",
    "        printmd(message)\n",
    "        \n",
    "    if inputUsername.value == \"\":\n",
    "        message = \"**Username:** {} (default)\".format(database_username)\n",
    "        printmd(message)\n",
    "    else:\n",
    "        database_username = inputUsername.value\n",
    "        message = \"**Username:** {}\".format(database_username)\n",
    "        printmd(message)\n",
    "        \n",
    "    if inputPassword.value == \"\":\n",
    "        message = \"**Password:** {} (default)\".format(database_password)\n",
    "        printmd(message)\n",
    "    else:\n",
    "        database_password = inputPassword.value\n",
    "        message = \"**Password:** ###########\"\n",
    "        printmd(message)\n",
    "    \n",
    "    printmd(\"------\")\n",
    "    db_connect()\n",
    "        \n",
    "button = widgets.Button(description=\"Connect\")\n",
    "ipd.display(button)\n",
    "button.on_click(on_button_click)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bar_plot(data,title,x,xLabel,y,yLabel,color=None,xAxisRotation=90):\n",
    "\n",
    "    # Bar plot\n",
    "    pylab.rcParams['figure.figsize'] = (12, 8)\n",
    "    seq_col_brew = sns.color_palette(\"Blues_r\", 1)\n",
    "    sns.color_palette(seq_col_brew)\n",
    "    if color != None:\n",
    "        plt = sns.barplot(x=x, y=y, data=data, color=color)\n",
    "    else:\n",
    "        plt = sns.barplot(x=x, y=y, data=data)\n",
    "        \n",
    "    # titles\n",
    "    plt.set_title(title,fontsize=30)\n",
    "    plt.set_xlabel(xLabel,fontsize=12)\n",
    "    plt.set_ylabel(yLabel,fontsize=12)\n",
    "    \n",
    "    # rotate x axis labels\n",
    "    for item in plt.get_xticklabels():\n",
    "        item.set_rotation(xAxisRotation)\n",
    "\n",
    "    # remove scientific notation\n",
    "    plt.ticklabel_format(style='plain', axis='y')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<span style='color:green'>**Connection successful!**</span>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "database_host = 'localhost'\n",
    "database_databasename = 'madlib'\n",
    "database_username = 'gpadmin'\n",
    "database_password = ''\n",
    "database_port = '8000'\n",
    "db_connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function\n",
    "def query_gpdb(query): \n",
    "\n",
    "    cur.execute(query)\n",
    "\n",
    "    colnames = [desc[0] for desc in cur.description]\n",
    "    return pd.DataFrame(cur.fetchall(), columns=colnames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "DROP TABLE IF EXISTS training_data;\n",
    "CREATE TABLE training_data (\n",
    "    a1 TEXT,\n",
    "    a2 TEXT,\n",
    "    a3 TEXT,\n",
    "    a4 FLOAT,\n",
    "    a5 FLOAT,\n",
    "    a6 INTEGER,\n",
    "    a7 INTEGER,\n",
    "    a8 INTEGER,\n",
    "    a9 INTEGER,\n",
    "    a10 INTEGER,\n",
    "    a11 INTEGER,\n",
    "    a12 FLOAT,\n",
    "    a13 FLOAT,\n",
    "    a14 FLOAT,\n",
    "    a15 INTEGER,\n",
    "    a16 FLOAT,\n",
    "    a17 FLOAT,\n",
    "    a18 FLOAT,\n",
    "    a19 FLOAT,\n",
    "    a20 FLOAT,\n",
    "    a21 FLOAT,\n",
    "    a22 FLOAT,\n",
    "    a23 FLOAT,\n",
    "    a24 INTEGER,\n",
    "    a25 FLOAT,\n",
    "    a26 FLOAT,\n",
    "    a27 FLOAT,\n",
    "    a28 FLOAT,\n",
    "    a29 FLOAT,\n",
    "    a30 FLOAT,\n",
    "    a31 FLOAT,\n",
    "    a32 FLOAT,\n",
    "    a33 FLOAT,\n",
    "    a34 FLOAT,\n",
    "    a35 FLOAT,\n",
    "    a36 FLOAT,\n",
    "    a37 FLOAT,\n",
    "    a38 FLOAT,\n",
    "    a39 FLOAT,\n",
    "    a40 FLOAT,\n",
    "    a41 FLOAT,\n",
    "    a42 INTEGER,\n",
    "    y TEXT\n",
    ");\n",
    "\n",
    "COPY training_data FROM '/home/gpadmin/network_data/training.csv' CSV DELIMITER ',';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%sql SET search_path=public,madlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "DROP TABLE IF EXISTS training_data_id;\n",
    "CREATE TABLE training_data_id AS\n",
    "SELECT ROW_NUMBER() OVER()-1 AS id, * FROM training_data;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "DROP TABLE training_data;\n",
    "ALTER TABLE training_data_id RENAME TO training_data;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "SELECT * FROM training_data ORDER BY id LIMIT 5;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "SELECT COUNT(*) FROM training_data;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Eval data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "DROP TABLE IF EXISTS eval_data;\n",
    "CREATE TABLE eval_data (\n",
    "    id INTEGER,\n",
    "    a1 TEXT,\n",
    "    a2 TEXT,\n",
    "    a3 TEXT,\n",
    "    a4 FLOAT,\n",
    "    a5 FLOAT,\n",
    "    a6 INTEGER,\n",
    "    a7 INTEGER,\n",
    "    a8 INTEGER,\n",
    "    a9 INTEGER,\n",
    "    a10 INTEGER,\n",
    "    a11 INTEGER,\n",
    "    a12 FLOAT,\n",
    "    a13 FLOAT,\n",
    "    a14 FLOAT,\n",
    "    a15 INTEGER,\n",
    "    a16 FLOAT,\n",
    "    a17 FLOAT,\n",
    "    a18 FLOAT,\n",
    "    a19 FLOAT,\n",
    "    a20 FLOAT,\n",
    "    a21 FLOAT,\n",
    "    a22 FLOAT,\n",
    "    a23 FLOAT,\n",
    "    a24 INTEGER,\n",
    "    a25 FLOAT,\n",
    "    a26 FLOAT,\n",
    "    a27 FLOAT,\n",
    "    a28 FLOAT,\n",
    "    a29 FLOAT,\n",
    "    a30 FLOAT,\n",
    "    a31 FLOAT,\n",
    "    a32 FLOAT,\n",
    "    a33 FLOAT,\n",
    "    a34 FLOAT,\n",
    "    a35 FLOAT,\n",
    "    a36 FLOAT,\n",
    "    a37 FLOAT,\n",
    "    a38 FLOAT,\n",
    "    a39 FLOAT,\n",
    "    a40 FLOAT,\n",
    "    a41 FLOAT,\n",
    "    a42 INTEGER\n",
    ");\n",
    "\n",
    "COPY eval_data FROM '/home/gpadmin/network_data/eval-rev2-1.csv' DELIMITER ',' CSV HEADER;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "SELECT * FROM eval_data ORDER BY id LIMIT 10;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "SELECT COUNT(*) FROM eval_data;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from imblearn.over_sampling import SMOTENC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training_data = %sql SELECT * FROM training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training_data = pd.read_csv(\"/Users/fmcquillan/Documents/Technical/vmw_ml_fun_jan2021/training.csv\", header=None) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = pd.read_csv(\"/Users/dominovaldano/Dropbox/vbetter/training.csv\", header=None) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data[42][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = list(training_data[42])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X_train = training_data.drop(labels=42, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_counts = %sql SELECT y,COUNT(*) AS c FROM training_data GROUP BY y HAVING COUNT(*) < 1000 ORDER BY c DESC;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Re-arrange training data columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = pd.read_csv('/Users/dominovaldano/Dropbox/vbetter/training.csv', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_floats(tbl):\n",
    "    query = \"SELECT COUNT(*) FROM {tbl} WHERE {col} != ROUND({col})\"\n",
    "    num_floats = []\n",
    "    for c in range(4,43):\n",
    "        col='a'+str(c)\n",
    "        cur.execute(query.format(col=col, tbl=tbl))\n",
    "        res = cur.fetchall()\n",
    "        num_float = res[0][0]\n",
    "        num_floats.append(num_float)\n",
    "    return num_floats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_floats = find_floats('eval_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "float_cols = [ i+3 for i in range(len(eval_floats)) if eval_floats[i] > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = [ x for x in range(3,41) if x not in float_cols ] # Drop column 41 because values are all 0, and drop 42 (y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(cat_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data[float_cols][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_float_cols = len(float_cols)\n",
    "num_int_cols = len(cat_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data[cat_cols][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_int = training_data[cat_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_int[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_float = training_data[float_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_text = training_data[[0,1,2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_xform = pd.concat([training_data_text, training_data_int, training_data_float, training_data[42]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_xform.columns = [ 'c' + str(i) for i in range(41)] + ['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_xform.to_csv('training_data_xform.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_int.columns = training_data_xform.columns[range(3,26)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(training_data_int.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_int[:50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1-Hot Encode and Scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: id",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-bf1bf544b616>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtraining_data_xform\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/Users/dominovaldano/Dropbox/vbetter/training_data_xform.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/dominovaldano/Library/Python/2.7/lib/python/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, doublequote, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    676\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 678\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    679\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/dominovaldano/Library/Python/2.7/lib/python/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 446\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    447\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m         \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/dominovaldano/Library/Python/2.7/lib/python/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1034\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'skipfooter not supported for iteration'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1035\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1036\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1037\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m         \u001b[0;31m# May alter columns / col_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/dominovaldano/Library/Python/2.7/lib/python/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1846\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1847\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1849\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_first_chunk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_low_memory\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_column_data\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_tokens\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: id"
     ]
    }
   ],
   "source": [
    "training_data_xform = pd.read_csv('/Users/dominovaldano/Dropbox/vbetter/training_data_xform.csv', header=None, dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>c0</td>\n",
       "      <td>c1</td>\n",
       "      <td>c2</td>\n",
       "      <td>c3</td>\n",
       "      <td>c4</td>\n",
       "      <td>c5</td>\n",
       "      <td>c6</td>\n",
       "      <td>c7</td>\n",
       "      <td>c8</td>\n",
       "      <td>c9</td>\n",
       "      <td>c10</td>\n",
       "      <td>c11</td>\n",
       "      <td>c12</td>\n",
       "      <td>c13</td>\n",
       "      <td>c14</td>\n",
       "      <td>c15</td>\n",
       "      <td>c16</td>\n",
       "      <td>c17</td>\n",
       "      <td>c18</td>\n",
       "      <td>c19</td>\n",
       "      <td>c20</td>\n",
       "      <td>c21</td>\n",
       "      <td>c22</td>\n",
       "      <td>c23</td>\n",
       "      <td>c24</td>\n",
       "      <td>c25</td>\n",
       "      <td>c26</td>\n",
       "      <td>c27</td>\n",
       "      <td>c28</td>\n",
       "      <td>c29</td>\n",
       "      <td>c30</td>\n",
       "      <td>c31</td>\n",
       "      <td>c32</td>\n",
       "      <td>c33</td>\n",
       "      <td>c34</td>\n",
       "      <td>c35</td>\n",
       "      <td>c36</td>\n",
       "      <td>c37</td>\n",
       "      <td>c38</td>\n",
       "      <td>c39</td>\n",
       "      <td>c40</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>TCP</td>\n",
       "      <td>PRIVATE</td>\n",
       "      <td>STAT02</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1952</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>255</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>290</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.08</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>class10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>TCP</td>\n",
       "      <td>HTTP</td>\n",
       "      <td>STAT10</td>\n",
       "      <td>305</td>\n",
       "      <td>1496</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1779</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>255</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "      <td>ICMP</td>\n",
       "      <td>ECR_I</td>\n",
       "      <td>STAT10</td>\n",
       "      <td>1032</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1079</td>\n",
       "      <td>0</td>\n",
       "      <td>511</td>\n",
       "      <td>0</td>\n",
       "      <td>255</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>255</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>511</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>class18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.0</td>\n",
       "      <td>TCP</td>\n",
       "      <td>PRIVATE</td>\n",
       "      <td>STAT06</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>924</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>255</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>223</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.06</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>class10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0     1        2       3     4     5   6   7   8   9  10   11   12   13  \\\n",
       "0 NaN   c0    c1       c2      c3    c4    c5  c6  c7  c8  c9  c10  c11  c12   \n",
       "1  0.0  TCP   PRIVATE  STAT02  0     0     0   0   0   0   0   0    0    0     \n",
       "2  1.0  TCP   HTTP     STAT10  305   1496  0   0   0   0   1   0    0    0     \n",
       "3  2.0  ICMP  ECR_I    STAT10  1032  0     0   0   0   0   0   0    0    0     \n",
       "4  3.0  TCP   PRIVATE  STAT06  0     0     0   0   0   0   0   0    0    0     \n",
       "\n",
       "     14   15   16   17   18   19   20   21   22   23   24   25   26   27  \\\n",
       "0  c13   c14  c15  c16  c17  c18  c19  c20  c21  c22  c23  c24  c25  c26   \n",
       "1  1952  0    16   0    16   0    0    0    0    255  0    0    290  0.0   \n",
       "2  1779  0    3    0    255  0    0    0    0    3    0    0    3    0.0   \n",
       "3  1079  0    511  0    255  0    0    0    0    255  0    0    511  0.0   \n",
       "4  924   0    13   0    13   0    0    0    0    255  0    0    223  0.0   \n",
       "\n",
       "     28    29    30   31   32   33    34   35   36   37    38    39   40   41  \\\n",
       "0  c27   c28   c29   c30  c31  c32  c33   c34  c35  c36  c37   c38   c39  c40   \n",
       "1  0.06  0.0   0.08  1.0  0.0  1.0  0.0   1.0  1.0  0.0  0.06  0.06  0.0  0.0   \n",
       "2  1.0   0.33  0.0   0.0  0.0  0.0  0.05  0.0  0.0  0.0  1.0   0.0   0.0  0.0   \n",
       "3  1.0   1.0   0.0   0.0  0.0  0.0  0.0   0.0  0.0  0.0  1.0   0.0   0.0  0.0   \n",
       "4  0.06  0.0   0.07  0.0  1.0  0.0  0.0   0.0  0.0  1.0  0.05  0.06  1.0  1.0   \n",
       "\n",
       "        42  \n",
       "0  y        \n",
       "1  class10  \n",
       "2  normal   \n",
       "3  class18  \n",
       "4  class10  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data_xform[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(23):\n",
    "    col = 'c' + str(i+3)\n",
    "    distinct = list(set(training_data_int[col]))\n",
    "    print('{} : {}'.format(col, len(distinct)))\n",
    "    if len(distinct) < 30:\n",
    "        print(distinct)\n",
    "    # counts = training_data_int.groupby(col)[col].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir(pd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = Counter(training_data_int['c21'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_xform.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "training_data_xform[training_data_xform.y == 'normal'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_values = np.array(list(set(training_data_xform['y'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_hist(col, df=training_data_xform):\n",
    "    for y in y_values:\n",
    "        df_y = df[df.y == y]\n",
    "        df_y.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_hist('c20')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_xform.groupby(['y', 'c21'])['y', 'c21'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql SELECT data_type, target_column, distinct_values, positive_values, zero_values, mean, variance FROM training_summary ORDER BY distinct_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a23, a35:  0-255 but mostly 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql SELECT a23,y, COUNT(*) FROM training_data GROUP BY 1,2 ORDER BY y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_counts = class_counts[:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sampling_strategy(classes):\n",
    "    n = [10] * (len(classes)-1) # Just take 10 samples of each\n",
    "    strat = { classes[i] : n[i] for i in range(len(classes)-1) }\n",
    "    return strat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strat = sampling_strategy(class_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_col_index = \"a1 a2 a3 a6 a7 a8 a9 a10 a11 a15 a24 a42\"\n",
    "cat_col_index = cat_col_index.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_col_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_col_index = [0, 1, 2, 5, 6, 7, 8, 9, 10, 14, 23, 41]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm = SMOTENC(categorical_features=cat_col_index, random_state=123, n_jobs=4,sampling_strategy={'class09' : 10 })\n",
    "X_trainres, y_trainres = sm.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_trainres.shape, y_trainres.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_trainres[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_trainres[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_trainres.shape = (4898434,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(X_trainres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[42] = y_trainres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = range(0,43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df[42] == 'class09']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_col_index = [0, 1, 2, 5, 6, 7, 8, 9, 10, 14, 23, 41]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql select * from training_data where y='class09';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %save -f 'smotenc.py' 1-32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yres = list(y_trainres[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = Counter(yres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in counts.keys():\n",
    "    print(\"{} : {}\".format(k,counts[k]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_res = pd.read_csv('df_res.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data.groupby(42)[42].count().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_res.groupby('y')['y'].count().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_res[df_res.y == 'class02']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data[training_data[42] == 'class02']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data.groupby(0)[0].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(training_data.groupby(1)[1].count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(training_data.groupby(2)[2].count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Smote Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'a' : [ 1, 2, 3, 4, 5], 'b' : [2, 4, 6, 8, 10], 'c' : [0, 1, 1, 0, 1], 'd' : [1, 1, 0, 0, 1], 't': ['hi', 'bye', 'please', 'welcome', 'welcome'], 'y' : ['YES', 'YES', 'NO','NO', 'NO']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df.drop('y', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = df.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm = SMOTENC(categorical_features=[4], k_neighbors=1, random_state=123, n_jobs=4,sampling_strategy={'NO' : 100 })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_trainres, y_trainres = sm.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_res = pd.DataFrame(X_trainres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_res[0] = df_res[0].apply(lambda x : int(round(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "round(3.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(df_res.apply)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for r in df_res:\n",
    "    print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(df_res.query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_res.insert(4, 'y', y_trainres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_res.sort_values('y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_res.groupby('y')[0].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from numpy.random import RandomState\n",
    "from sklearn.datasets import make_classification\n",
    "from imblearn.over_sampling import SMOTENC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_classification(n_classes=2, class_sep=2,\n",
    "weights=[0.1, 0.9], n_informative=3, n_redundant=1, flip_y=0, n_features=20, n_clusters_per_class=1, n_samples=1000, random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<a id=\"external_table\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Audit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"summary_statistics\"></a>\n",
    "Summary Statistics\n",
    "\n",
    "https://madlib.apache.org/docs/latest/group__grp__summary.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "DROP TABLE IF EXISTS training_summary;\n",
    "SELECT * FROM madlib.summary( 'training_data',   -- Source table\n",
    "                              'training_summary'    -- Output table\n",
    "                            );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "SELECT * FROM training_summary;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "DROP TABLE IF EXISTS eval_summary;\n",
    "SELECT * FROM madlib.summary( 'eval_data',   -- Source table\n",
    "                              'eval_summary'    -- Output table\n",
    "                            );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "SELECT * FROM eval_summary;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<a id=\"de_categorical\"></a>\n",
    "#### Categorical Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "catColumns = ['a1','a2','a3', 'a6','a7','a8', 'a9',\n",
    "              'a10','a11', 'a15','a24','a42',\n",
    "              'y']\n",
    "\n",
    "def bar_plot(data,title,x,xLabel,y,yLabel,color=None,xAxisRotation=90):\n",
    "\n",
    "    # Bar plot\n",
    "    pylab.rcParams['figure.figsize'] = (12, 8)\n",
    "    seq_col_brew = sns.color_palette(\"Blues_r\", 1)\n",
    "    sns.color_palette(seq_col_brew)\n",
    "    if color != None:\n",
    "        plt = sns.barplot(x=x, y=y, data=data, color=color)\n",
    "    else:\n",
    "        plt = sns.barplot(x=x, y=y, data=data)\n",
    "        \n",
    "    # titles\n",
    "    plt.set_title(title,fontsize=30)\n",
    "    plt.set_xlabel(xLabel,fontsize=12)\n",
    "    plt.set_ylabel(yLabel,fontsize=12)\n",
    "    \n",
    "    # rotate x axis labels\n",
    "    for item in plt.get_xticklabels():\n",
    "        item.set_rotation(xAxisRotation)\n",
    "\n",
    "    # remove scientific notation\n",
    "    plt.ticklabel_format(style='plain', axis='y')\n",
    "\n",
    "\n",
    "def get_cat_data_frame(col):\n",
    "    query = \"\"\"\n",
    "        SELECT *\n",
    "              ,round((record_count * 100.0) / sum(record_count) OVER(),2) AS perc_records\n",
    "        FROM (\n",
    "            SELECT {} AS col\n",
    "                  ,count(*) AS record_count\n",
    "            FROM public.training_data\n",
    "            GROUP BY 1\n",
    "        ) foo\n",
    "        ORDER BY perc_records DESC\n",
    "    \"\"\".format(col)\n",
    "    cur.execute(query)\n",
    "\n",
    "    colnames = [desc[0] for desc in cur.description]\n",
    "    return pd.DataFrame(cur.fetchall(), columns=colnames)\n",
    "    \n",
    "def on_cat_selection(res):\n",
    "    if res['type'] == 'change' and res['name'] == 'value':\n",
    "        ipd.clear_output()\n",
    "        printmd(\"-----\\n **Select Column:**\")\n",
    "        ipd.display(catDropdown)\n",
    "        df = get_cat_data_frame(res['new'])\n",
    "        bar_plot(df,res['new'],\"col\",res['new'],\"perc_records\",\"% Records\", None, 0)\n",
    "    \n",
    "catDropdown = widgets.Dropdown(\n",
    "    options=catColumns,\n",
    "    value=catColumns[0],\n",
    "    description='Column:',\n",
    "    disabled=False,\n",
    ")\n",
    "\n",
    "catDropdown.observe(on_cat_selection)\n",
    "printmd(\"-----\\n **Select Column:**\")\n",
    "ipd.display(catDropdown)\n",
    "df = get_cat_data_frame(catColumns[0])\n",
    "bar_plot(df,catColumns[0],\"col\",catColumns[0],\"perc_records\",\"% Records\", None, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "* Low % of values in any one class can skew model results and/or create unstable model. In practice we may consider merging and/or excluding some groups. (e.g. a4: [i], a5: [gg], a7: [z,j,dd,n,o), a13: [s,p])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<a id=\"de_continuous\"></a>\n",
    "#### Continuous Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "contColumns = ['a4', 'a5','a12', 'a13', 'a14', 'a16', \n",
    "               'a17', 'a18', 'a19', 'a20', 'a21', \n",
    "               'a22', 'a23', 'a25', 'a26', 'a27', \n",
    "               'a28', 'a29', 'a30', 'a31', 'a32', \n",
    "               'a33', 'a34', 'a35', 'a36', 'a37', \n",
    "               'a38', 'a39', 'a40', 'a41']\n",
    "sliderValue = 20\n",
    "colName = contColumns[0]\n",
    "\n",
    "def get_cont_data_frame(col, buckets):\n",
    "    query = \"\"\"\n",
    "        WITH aggs AS (\n",
    "            SELECT min({c}) AS min,\n",
    "                   max({c}) AS max\n",
    "              FROM training_data\n",
    "        )\n",
    "        SELECT width_bucket({c}, min, max, {b}-1) AS bucket,\n",
    "               ('[' || min({c}) || ',' || max({c}) || ')')::text as range,\n",
    "               count(*) as freq\n",
    "        FROM training_data, aggs\n",
    "        GROUP BY bucket\n",
    "        ORDER BY bucket\n",
    "    \"\"\".format(c=col, b=buckets)\n",
    "    cur.execute(query)\n",
    "\n",
    "    colnames = [desc[0] for desc in cur.description]\n",
    "    return pd.DataFrame(cur.fetchall(), columns=colnames)\n",
    "    \n",
    "def graph_reset():\n",
    "    ipd.clear_output()\n",
    "    printmd(\"-----\\n\")\n",
    "    ipd.display(widgets.HBox((contDropdown,bucketsSlider)))\n",
    "    printmd(\"-----\\n\")\n",
    "    df = get_cont_data_frame(colName,sliderValue)\n",
    "    bar_plot(df,colName,\"range\",colName,\"freq\",\"Frequency\", \"#4378E2\")    \n",
    "    \n",
    "def on_cont_selection(res):\n",
    "    global colName\n",
    "    if res['type'] == 'change' and res['name'] == 'value':\n",
    "        colName = res['new']\n",
    "        graph_reset()\n",
    "        \n",
    "def on_slider_selection(res):\n",
    "    global sliderValue\n",
    "    if res['new'] == {} and res['old']:\n",
    "        sliderValue = res['old']['value']\n",
    "        graph_reset()\n",
    "    \n",
    "# Look at log transforms\n",
    "#colsAddLogs = contColumns + [\"log({} + 1)\".format(c) for c in contColumns]\n",
    "colsAddLogs = contColumns\n",
    "\n",
    "contDropdown = widgets.Dropdown(\n",
    "    options=colsAddLogs,\n",
    "    value=colsAddLogs[0],\n",
    "    description='Column:',\n",
    "    disabled=False,\n",
    ")\n",
    "\n",
    "bucketsSlider = widgets.IntSlider(\n",
    "    value=sliderValue,\n",
    "    min=5,\n",
    "    max=50,\n",
    "    step=1,\n",
    "    description='# Buckets:',\n",
    "    disabled=False,\n",
    "    continuous_update=False,\n",
    "    orientation='horizontal',\n",
    "    readout=True,\n",
    "    readout_format='d'\n",
    ")\n",
    "\n",
    "contDropdown.observe(on_cont_selection)\n",
    "bucketsSlider.observe(on_slider_selection)\n",
    "\n",
    "graph_reset()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "* a15 large number of outliers - consider correcting\n",
    "* Consider variable transformation if test non-tree based algorithm\n",
    "* Histogram values are being calculated in the database - minimal data movement back to client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "DROP TABLE IF EXISTS training_data_encoded, training_data_encoded_dictionary;\n",
    "SELECT madlib.encode_categorical_variables (\n",
    "        'training_data',            -- Source table\n",
    "        'training_data_encoded',      -- Output table\n",
    "        'a1, a2, a3'                        -- Categorical columns\n",
    "        );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "select * from training_data_encoded limit 5;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Sample training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "drop table if exists training_data_work1;\n",
    "create table training_data_work1 as\n",
    "(select * from training_data_encoded where y='class19' \n",
    "                                            or y='class12'\n",
    "                                            or y='class13');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "drop table if exists training_data_work2, training_data_work2_summary;\n",
    "select madlib.cols2vec('training_data_work1',\n",
    "                       'training_data_work2',\n",
    "                       '*',\n",
    "                       'y',\n",
    "                       'y'\n",
    "                       );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "ALTER TABLE training_data_work2 ADD column pid serial;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "DROP TABLE IF EXISTS training_data_work3;\n",
    "\n",
    "CREATE TABLE training_data_work3 AS\n",
    "(SELECT * FROM madlib.kmeanspp(\n",
    "    'training_data_work2',                  -- points table\n",
    "    'feature_vector',                      -- column name in point table\n",
    "    3,\n",
    "    'madlib.dist_norm1',   -- distance function\n",
    "    'madlib.avg',                  -- aggregate function\n",
    "    20,                            -- max iterations\n",
    "    0.001                         -- minimum fraction of centroids reassigned to continue iterating\n",
    "));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "select * from training_data_work3;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "DROP TABLE IF EXISTS point_cluster_map;\n",
    "CREATE TABLE point_cluster_map AS\n",
    "SELECT data.*, (madlib.closest_column(centroids, feature_vector, 'madlib.squared_dist_norm2')).*\n",
    "FROM training_data_work2 as data, training_data_work3;\n",
    "ALTER TABLE point_cluster_map RENAME column_id to cluster_id; -- change column name\n",
    "SELECT y, pid, cluster_id, distance FROM point_cluster_map ORDER BY cluster_id, distance desc;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "SELECT * FROM madlib.simple_silhouette( 'training_data_work2',          -- Input points table\n",
    "                                              'feature_vector',              -- Points column in input table\n",
    "                                              (select centroids from training_data_work3),           -- Column in centroids table containing centroids\n",
    "                                              'madlib.squared_dist_norm2'   -- Distance function\n",
    "                                      );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "DROP TABLE IF EXISTS km_points_silh;\n",
    "SELECT * FROM madlib.simple_silhouette_points( 'training_data_work2',          -- Input points table\n",
    "                                              'km_points_silh',      -- Output table\n",
    "                                              'pid',                 -- Point ID column in input table\n",
    "                                              'feature_vector',              -- Points column in input table\n",
    "                                              'training_data_work3',           -- Centroids table\n",
    "                                              'centroids',           -- Column in centroids table containing centroids\n",
    "                                              'madlib.squared_dist_norm2'   -- Distance function\n",
    "                                      );\n",
    "SELECT * FROM km_points_silh ORDER BY centroid_id;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "whole table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "drop table if exists training_data_work10, training_data_work10_summary;\n",
    "select madlib.cols2vec('training_data_encoded',\n",
    "                       'training_data_work10',\n",
    "                       '*',\n",
    "                       'y',\n",
    "                       'y'\n",
    "                       );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "DROP TABLE IF EXISTS point_cluster_map;\n",
    "CREATE TABLE point_cluster_map AS\n",
    "SELECT data.*, (madlib.closest_column(centroids, feature_vector, 'madlib.squared_dist_norm2')).*\n",
    "FROM training_data_work10 as data, training_data_work3;\n",
    "ALTER TABLE point_cluster_map RENAME column_id to cluster_id; -- change column name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "select * from point_cluster_map limit 5;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%sql \n",
    "select count(*) from point_cluster_map where cluster_id = 0 and distance < 130415.0;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "DROP TABLE IF EXISTS k_auto, k_auto_summary;\n",
    "\n",
    "SELECT madlib.kmeanspp_auto(\n",
    "    'training_data_work2',                  -- points table\n",
    "    'k_auto',                      -- output table\n",
    "    'feature_vector',                      -- column name in point table\n",
    "    ARRAY[2,3,4],              -- k values to try\n",
    "    'madlib.squared_dist_norm2',   -- distance function\n",
    "    'madlib.avg',                  -- aggregate function\n",
    "    20,                            -- max iterations\n",
    "    0.001,                         -- minimum fraction of centroids reassigned to continue iterating\n",
    "    1.0,                           -- centroid seed\n",
    "    'silhouette'                         -- k selection algorithm (silhouette or elbow or both)\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "SELECT * FROM k_auto_summary;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "SELECT * FROM k_auto ORDER BY k;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# get range of k values tested\n",
    "k_range = %sql SELECT k FROM k_auto ORDER BY k;\n",
    "\n",
    "# outer loop on k\n",
    "# plot clusters for each k value\n",
    "for n_clusters in k_range:\n",
    "    \n",
    "    # create table mapping each point to its centroid\n",
    "    kval = n_clusters[0]\n",
    "    %sql DROP TABLE IF EXISTS k_plot1;\n",
    "    %sql CREATE TABLE k_plot1 AS (SELECT data.*, (madlib.closest_column(centroids, feature_vector, 'madlib.squared_dist_norm2')).column_id as cluster_id FROM training_data_work2 as data, k_auto WHERE k=$kval);\n",
    "\n",
    "    # get info from tables and reshape to np arrays    \n",
    "    # number of points\n",
    "    num_points_proxy= %sql SELECT COUNT(*) FROM k_plot1;\n",
    "    num_points= num_points_proxy[0][0]\n",
    "    \n",
    "    # points\n",
    "    points_proxy = %sql SELECT feature_vector FROM k_plot1 ORDER BY pid;\n",
    "    points = np.array(points_proxy).reshape(num_points,123) \n",
    "    \n",
    "    # cluster id\n",
    "    cluster_id_proxy = %sql SELECT cluster_id FROM k_plot1 ORDER BY pid;\n",
    "    cluster_id = np.array(cluster_id_proxy).reshape(num_points)\n",
    "    \n",
    "    # centroids\n",
    "    centroids_proxy = %sql SELECT centroids FROM k_auto WHERE k=$kval;\n",
    "    centers = np.array(centroids_proxy[0][0]).reshape(kval,123)\n",
    "    \n",
    "    # The silhouette_score gives the average value for all the samples.\n",
    "    # This gives a perspective into the density and separation of the formed\n",
    "    # clusters\n",
    "    silhouette_avg = %sql SELECT silhouette FROM k_auto WHERE k=$kval;\n",
    "    print(\"For n_clusters =\", kval,\n",
    "          \"The average silhouette_score is :\", silhouette_avg)\n",
    "    \n",
    "    # Create a subplot with 1 row and 2 columns\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "    fig.set_size_inches(18, 7)\n",
    "      \n",
    "    # The 1st subplot is the silhouette plot\n",
    "    # The silhouette coefficient can range from -1, 1 but in this example all\n",
    "    # lie within [-0.1, 1]\n",
    "    ax1.set_xlim([-0.1, 1])\n",
    "    # The (n_clusters+1)*10 is for inserting blank space between silhouette\n",
    "    # plots of individual clusters, to demarcate them clearly.\n",
    "    len_X = %sql select count(*) from training_data_work2;\n",
    "    len_X = len_X[0][0]\n",
    "    ax1.set_ylim([0, len_X + (kval + 1) * 10])\n",
    "    \n",
    "    y_lower = 10\n",
    "    \n",
    "    # inner loop on number of centroids \n",
    "    for i in range(kval):\n",
    "\n",
    "        %sql DROP TABLE IF EXISTS points_distr1;\n",
    "        %sql SELECT * FROM madlib.simple_silhouette_points( 'training_data_work2', 'points_distr1', 'pid', 'feature_vector', (SELECT centroids FROM k_auto WHERE k=$kval), 'madlib.squared_dist_norm2');\n",
    "        ith_cluster_silhouette_values_proxy = %sql SELECT silh from points_distr1 WHERE centroid_id=$i ORDER BY silh;\n",
    "        ith_cluster_silhouette_values = np.array(ith_cluster_silhouette_values_proxy).reshape(len(ith_cluster_silhouette_values_proxy))\n",
    "        \n",
    "        size_cluster_i_proxy = %sql SELECT COUNT(*) from points_distr1 WHERE centroid_id=$i;\n",
    "        size_cluster_i = size_cluster_i_proxy[0][0]\n",
    "\n",
    "        y_upper = y_lower + size_cluster_i\n",
    "\n",
    "        color = cm.nipy_spectral(float(i) / kval)\n",
    "        ax1.fill_betweenx(np.arange(y_lower, y_upper), \n",
    "                  0, ith_cluster_silhouette_values, \n",
    "                  facecolor=color, edgecolor=color, alpha=0.7);\n",
    "        \n",
    "        # Label the silhouette plots with their cluster numbers at the middle\n",
    "        ax1.text(-0.05, y_lower + 0.5 * size_cluster_i, str(i));\n",
    "\n",
    "        # Compute the new y_lower for next plot\n",
    "        y_lower = y_upper + 10  # 10 for the 0 samples\n",
    "           \n",
    "    ax1.set_title(\"Silhouette plot for the various clusters.\")\n",
    "    ax1.set_xlabel(\"Silhouette coefficient values\")\n",
    "    ax1.set_ylabel(\"Cluster label\")\n",
    "\n",
    "    # The vertical line for average silhouette score of all the values\n",
    "    ax1.axvline(x=silhouette_avg, color=\"red\", linestyle=\"--\")\n",
    "\n",
    "    ax1.set_yticks([])  # Clear the yaxis labels / ticks\n",
    "    ax1.set_xticks([-0.1, 0, 0.2, 0.4, 0.6, 0.8, 1])\n",
    "    \n",
    "    # 2nd Plot showing the actual clusters formed\n",
    "    centroids = %sql SELECT centroid_id FROM points_distr1 ORDER BY pid;\n",
    "    cluster_labels = np.array(centroids).reshape(len(centroids))\n",
    "    \n",
    "    colors = cm.nipy_spectral(cluster_labels.astype(float) / kval)\n",
    "    #ax2.scatter(X[:, 0], X[:, 1], marker='.', s=30, lw=0, alpha=0.7,\n",
    "    #            c=colors, edgecolor='k')\n",
    "\n",
    "    # Labeling the clusters\n",
    "    # Draw white circles at cluster centers\n",
    "    #ax2.scatter(centers[:, 0], centers[:, 1], marker='o',\n",
    "    #            c=\"white\", alpha=1, s=200, edgecolor='k')\n",
    "\n",
    "    #for i, c in enumerate(centers):\n",
    "    #    ax2.scatter(c[0], c[1], marker='$%d$' % i, alpha=1,\n",
    "    #                s=50, edgecolor='k')\n",
    "\n",
    "    #ax2.set_title(\"Visualization of the clustered data.\")\n",
    "    #ax2.set_xlabel(\"Feature space for the 1st feature\")\n",
    "    #ax2.set_ylabel(\"Feature space for the 2nd feature\")\n",
    "\n",
    "    plt.suptitle((\"Silhouette analysis for KMeans clustering on sample data \"\n",
    "                  \"with n_clusters = %d\" % kval),\n",
    "                 fontsize=14, fontweight='bold')\n",
    "\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "len_X = %sql select count(*) from training_data_work2;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "len_X[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_res = %sql SELECT * FROM 'df_res.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Nearest neighbors - v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "drop table if exists temp1;\n",
    "create table temp1 as\n",
    "select * from training_data_encoded where y='class19' or y='class12';\n",
    "select * from temp1;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "DROP TABLE IF EXISTS temp1_summary;\n",
    "SELECT * FROM madlib.summary( 'temp1',   -- Source table\n",
    "                              'temp1_summary',    -- Output table\n",
    "                              NULL,      -- summarize all columns\n",
    "                              'y'    -- grouping \n",
    "                            );\n",
    "select group_by_value, lower(target_column)::VARCHAR, column_number, mean from temp1_summary  where group_by='y' order by group_by, group_by_value, column_number;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "DROP TABLE IF EXISTS temp2;\n",
    "create table temp2 as\n",
    "select group_by_value, target_column, mean from temp1_summary \n",
    "  where (target_column='a4' or target_column='a5') and group_by_value<>'None'\n",
    "  order by group_by_value, target_column;\n",
    "select * from temp2 order by group_by_value, target_column;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "DROP TABLE IF EXISTS temp3;\n",
    "SELECT madlib.pivot('temp2', 'temp3', 'group_by_value', 'target_column', 'mean');\n",
    "SELECT * FROM temp3;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Nearest neighbors - v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "drop table if exists temp1;\n",
    "  create table temp1 as \n",
    "  select * from training_data;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "drop table if exists temp2;\n",
    "  create table temp2 as  \n",
    "  select LOWER(a1) as a1, LOWER(a2) as a2, LOWER(a3) as a3, \n",
    "    a4,\n",
    "    a5,\n",
    "    a6 ,\n",
    "    a7 ,\n",
    "    a8 ,\n",
    "    a9 ,\n",
    "    a10 ,\n",
    "    a11 ,\n",
    "    a12 ,\n",
    "    a13 ,\n",
    "    a14 ,\n",
    "    a15 ,\n",
    "    a16 ,\n",
    "    a17 ,\n",
    "    a18 ,\n",
    "    a19 ,\n",
    "    a20 ,\n",
    "    a21 ,\n",
    "    a22 ,\n",
    "    a23 ,\n",
    "    a24 ,\n",
    "    a25 ,\n",
    "    a26 ,\n",
    "    a27 ,\n",
    "    a28 ,\n",
    "    a29 ,\n",
    "    a30 ,\n",
    "    a31 ,\n",
    "    a32 ,\n",
    "    a33 ,\n",
    "    a34 ,\n",
    "    a35 ,\n",
    "    a36 ,\n",
    "    a37 ,\n",
    "    a38 ,\n",
    "    a39 ,\n",
    "    a40 ,\n",
    "    a41 ,\n",
    "    a42 ,\n",
    "    y from temp1;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "select * from temp2 limit 5;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "DROP TABLE IF EXISTS training_data_encoded, training_data_encoded_dictionary;\n",
    "SELECT madlib.encode_categorical_variables (\n",
    "        'temp2',            -- Source table\n",
    "        'training_data_encoded',      -- Output table\n",
    "        'a1, a2, a3'                        -- Categorical columns\n",
    "        );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "select * from training_data_encoded limit 5;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "DROP TABLE IF EXISTS training_data_encoded_summary;\n",
    "SELECT * FROM madlib.summary( 'training_data_encoded',   -- Source table\n",
    "                              'training_data_encoded_summary',    -- Output table\n",
    "                              NULL,      -- summarize all columns\n",
    "                              'y',    -- grouping \n",
    "                             NULL,\n",
    "                             NULL,\n",
    "                             NULL,\n",
    "                             NULL,\n",
    "                             NULL,\n",
    "                             5\n",
    "                            );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "select group_by, group_by_value, target_column, column_number, mean, variance, min, max from training_data_encoded_summary where target_column='a5' order by group_by, group_by_value, column_number;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "drop table if exists training_data_encoded_summary_all;\n",
    "create table training_data_encoded_summary_all as\n",
    "  select * from training_data_encoded_summary where group_by is NULL;\n",
    "select * from training_data_encoded_summary_all order by column_number;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "drop table if exists work1;\n",
    "create table work1 as \n",
    "  select * from training_data_encoded limit 10;\n",
    "select * from work1;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "drop table if exists drop table if exists work2;\n",
    "create table work2 as\n",
    "DROP TABLE IF EXISTS training_data_encoded_summary;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "drop table if exists temp3;\n",
    "create table temp3 as\n",
    "select * from training_data_encoded where y='class19';\n",
    "select * from temp3;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "DROP TABLE IF EXISTS temp4;\n",
    "create table temp4 as\n",
    "select * from temp3_summary where group_by = 'y';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "DROP TABLE IF EXISTS temp5;\n",
    "SELECT madlib.pivot('temp4', 'temp5', 'group_by_value', 'target_column', 'mean');\n",
    "SELECT * FROM temp5;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "drop table if exists temp6, temp6_summary;\n",
    "select madlib.cols2vec('temp5',\n",
    "                       'temp6',\n",
    "                       '*',\n",
    "                       'group_by_value',\n",
    "                       'group_by_value'\n",
    "                       );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "alter table temp6\n",
    "rename column group_by_value to y;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "select * from temp6;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "drop table if exists temp7, temp7_summary;\n",
    "select madlib.cols2vec('training_data_encoded',\n",
    "                       'temp7',\n",
    "                       '*',\n",
    "                       'y',\n",
    "                       'y'\n",
    "                       );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "select * from temp7 limit 5;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "create table temp8 as\n",
    "  select temp6.y as from_class , temp7.y as to_class, madlib.squared_dist_norm2(temp6.feature_vector, temp7.feature_vector) from temp6, temp7;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "select * from temp8 order by squared_dist_norm2 asc limit 100;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "----\n",
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<a id=\"fe_continuous\"></a>\n",
    "#### Continuous Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# continuos features (seperated out incase feature transformations are required)\n",
    "query = \"\"\"\n",
    "    DROP TABLE IF EXISTS public.model_inputs_cont;\n",
    "    CREATE TABLE public.model_inputs_cont AS\n",
    "    SELECT _id\n",
    "          ,a16 AS approval\n",
    "          ,a2\n",
    "          ,a3\n",
    "          ,a8\n",
    "          ,a11\n",
    "          ,a14\n",
    "          ,a15\n",
    "    FROM public.credit_application_data\n",
    "    DISTRIBUTED BY (_id);\n",
    "    SELECT * FROM public.model_inputs_cont LIMIT 0;\n",
    "\"\"\"\n",
    "cur.execute(query)\n",
    "\n",
    "contFeatureNames = [desc[0] for desc in cur.description]\n",
    "contFeatureNames.remove('_id')\n",
    "contFeatureNames.remove('approval')\n",
    "\n",
    "query = \"\"\"\n",
    "    SELECT *\n",
    "    FROM public.model_inputs_cont\n",
    "\"\"\"\n",
    "df = query_gpdb(query)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<a id=\"fe_one_hot\"></a>\n",
    "#### One Hot Encode Categorical Features\n",
    "\n",
    "https://madlib.apache.org/docs/latest/group__grp__encode__categorical.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# encode categorical features\n",
    "query = \"\"\"\n",
    "    DROP TABLE IF EXISTS public.model_inputs_cat;\n",
    "    SELECT madlib.encode_categorical_variables (\n",
    "        'public.credit_application_data',\n",
    "        'public.model_inputs_cat',\n",
    "        'a1,a4,a5,a6,a7,a9,a10,a12,a13',\n",
    "        NULL,\n",
    "        '_id',\n",
    "        NULL,\n",
    "        'a1=b, a4=y, a5=p, a6=x, a7=z, a9=false, a10=false, a12=false, a13=s'\n",
    "    );\n",
    "\"\"\"\n",
    "cur.execute(query)\n",
    "\n",
    "query = \"\"\"\n",
    "    SELECT *\n",
    "    FROM public.model_inputs_cat\n",
    "\"\"\"\n",
    "cur.execute(query)\n",
    "\n",
    "colnames = [desc[0] for desc in cur.description]\n",
    "df = pd.DataFrame(cur.fetchall(), columns=colnames)\n",
    "\n",
    "colnames.remove('_id')\n",
    "catFeatureNames = colnames\n",
    "featureNames = contFeatureNames + catFeatureNames\n",
    "print(featureNames)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<a id=\"fe_combine\"></a>\n",
    "#### Combine Continuous & Categorical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# combine feature tables\n",
    "query = \"\"\"\n",
    "    DROP TABLE IF EXISTS public.model_inputs;\n",
    "    CREATE TABLE public.model_inputs AS\n",
    "    SELECT *\n",
    "    FROM public.model_inputs_cat\n",
    "    JOIN public.model_inputs_cont\n",
    "    USING (_id);\n",
    "\"\"\"\n",
    "cur.execute(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<a id=\"fe_cats_dep\"></a>\n",
    "#### Plot Categorical Features By Response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def bar_plot_groupby(data, title,x,xLabel,y,yLabel,groupby,color=None,axisRotation=90):\n",
    "\n",
    "    # Bar plot\n",
    "    pylab.rcParams['figure.figsize'] = (12, 8)\n",
    "    seq_col_brew = sns.color_palette(\"Blues_r\", 1)\n",
    "    sns.color_palette(seq_col_brew)\n",
    "    if color != None:\n",
    "        plt = sns.barplot(x=x, y=y, data=data, color=color, hue=groupby)\n",
    "    else:\n",
    "        plt = sns.barplot(x=x, y=y, data=data, hue=groupby)\n",
    "        \n",
    "    # titles\n",
    "    plt.set_title(title,fontsize=30)\n",
    "    plt.set_xlabel(xLabel,fontsize=16)\n",
    "    plt.set_ylabel(yLabel,fontsize=16)\n",
    "    \n",
    "    # rotate x axis labels\n",
    "    for item in plt.get_xticklabels():\n",
    "        item.set_rotation(axisRotation)\n",
    "\n",
    "    # remove scientific notation\n",
    "    plt.ticklabel_format(style='plain', axis='y')\n",
    "\n",
    "def get_cat_gb_data_frame(col):\n",
    "    query = \"\"\"\n",
    "        SELECT *\n",
    "              ,round((record_count * 100.0) / sum(record_count) OVER(PARTITION BY col),2) AS perc_records\n",
    "        FROM (\n",
    "            SELECT {} AS col\n",
    "                  ,approval\n",
    "                  ,count(*) AS record_count\n",
    "            FROM public.model_inputs\n",
    "            GROUP BY 1,2\n",
    "        ) foo\n",
    "        ORDER BY 1,2\n",
    "    \"\"\".format(col)\n",
    "    cur.execute(query)\n",
    "\n",
    "    colnames = [desc[0] for desc in cur.description]\n",
    "    return pd.DataFrame(cur.fetchall(), columns=colnames)\n",
    "    \n",
    "def on_cat_gb_selection(res):\n",
    "    if res['type'] == 'change' and res['name'] == 'value':\n",
    "        ipd.clear_output()\n",
    "        printmd(\"-----\\n **Select Column:**\")\n",
    "        ipd.display(catGPDropdown)\n",
    "        df = get_cat_gb_data_frame(res['new'])\n",
    "        bar_plot_groupby(df,res['new'],\"col\",res['new'],\"perc_records\",\"% Class Records\", \"approval\")\n",
    "    \n",
    "catGPDropdown = widgets.Dropdown(\n",
    "    options=catFeatureNames,\n",
    "    value=catFeatureNames[0],\n",
    "    description='Column:',\n",
    "    disabled=False,\n",
    ")\n",
    "\n",
    "catGPDropdown.observe(on_cat_gb_selection)\n",
    "printmd(\"-----\\n **Select Column:**\")\n",
    "ipd.display(catGPDropdown)\n",
    "df = get_cat_gb_data_frame(catFeatureNames[0])\n",
    "bar_plot_groupby(df,catFeatureNames[0],\"col\",catFeatureNames[0],\"perc_records\",\"% Class Records\",\"approval\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "* a9_true appears to be a strong variable due to seperate between classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<a id=\"fe_chi_sq\"></a>\n",
    "#### Chi-squared testing\n",
    "\n",
    "https://en.wikipedia.org/wiki/Chi-squared_test\n",
    "\n",
    "https://madlib.apache.org/docs/latest/group__grp__stats__tests.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def chi2_gof_test(feature_name, response):\n",
    "    query = \"\"\"\n",
    "        WITH freq AS (\n",
    "            SELECT {feature_name}\n",
    "                  ,{response}\n",
    "                  ,count(*) AS observed\n",
    "            FROM public.model_inputs\n",
    "            GROUP BY 1,2\n",
    "        )\n",
    "        SELECT '{feature_name}' AS feature_name\n",
    "              ,'{response}' AS response\n",
    "              ,(madlib.chi2_gof_test(observed, expected, deg_freedom)).*\n",
    "        FROM (\n",
    "            SELECT observed\n",
    "                  ,sum(observed) OVER (PARTITION BY {feature_name})::DOUBLE PRECISION\n",
    "                       * sum(observed) OVER (PARTITION BY {response}) AS expected\n",
    "            FROM freq\n",
    "        ) l, (\n",
    "            SELECT (count(distinct {feature_name}) - 1) * (count(distinct {response}) - 1) AS deg_freedom\n",
    "            FROM freq\n",
    "        ) r;\n",
    "    \"\"\".format(feature_name=feature_name, response=response)\n",
    "    cur.execute(query)\n",
    "\n",
    "    colnames = [desc[0] for desc in cur.description]\n",
    "    return pd.DataFrame(cur.fetchall(), columns=colnames)\n",
    "\n",
    "def chi2_gof_test_multi(feature_list, response):\n",
    "    res = chi2_gof_test(feature_list[0], response)\n",
    "    for i in range(1,len(feature_list)):\n",
    "        res = res.append(chi2_gof_test(feature_list[i], response))\n",
    "        \n",
    "    return res\n",
    "\n",
    "chi2_results = chi2_gof_test_multi(catFeatureNames, 'approval')\n",
    "chi2_results.sort_values('phi', inplace=True)\n",
    "ipd.display(chi2_results)\n",
    "bar_plot(chi2_results, \"Chi-Squared Testing\",\"feature_name\",\"Feature Name\",\"phi\",\"Test Statistic\", \"#4378E2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<a id=\"fe_corr\"></a>\n",
    "#### Correlation Testing\n",
    "\n",
    "https://madlib.apache.org/docs/latest/group__grp__correlation.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# calc correlations\n",
    "query = \"\"\"\n",
    "    DROP TABLE IF EXISTS public.feature_correlations, public.feature_correlations_summary;\n",
    "    SELECT madlib.correlation( \n",
    "        'public.training_data',\n",
    "        'public.feature_correlations',\n",
    "        '{}'\n",
    "    );\n",
    "    SELECT * \n",
    "    FROM public.feature_correlations\n",
    "    ORDER BY column_position;\n",
    "\"\"\".format(\",\".join(contFeatureNames))\n",
    "corr = query_gpdb(query)\n",
    "\n",
    "corr.drop('column_position', 'columns', inplace=True)\n",
    "corr.set_index('variable', True, False, True)\n",
    "corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "DROP TABLE IF EXISTS public.feature_correlations, public.feature_correlations_summary;\n",
    "SELECT madlib.correlation( \n",
    "        'public.training_data',\n",
    "        'public.feature_correlations'\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = %sql SELECT * FROM public.feature_correlations ORDER BY column_position;\n",
    "corr = corr.DataFrame()\n",
    "corr.drop('column_position', 'columns', inplace=True)\n",
    "corr.set_index('variable', True, False, True)\n",
    "corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Generate a mask for the upper triangle\n",
    "mask = np.zeros_like(corr, dtype=np.bool)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "\n",
    "# Set up the matplotlib figure\n",
    "#f, ax = plt.subplots(figsize=(11, 9))\n",
    "f, ax = plt.subplots(figsize=(13, 11))\n",
    "\n",
    "# Generate a custom diverging colormap\n",
    "cmap = sns.diverging_palette(220, 10, as_cmap=True)\n",
    "\n",
    "# Draw the heatmap with the mask and correct aspect ratio\n",
    "sns.heatmap(corr, mask=mask, cmap=cmap, vmax=.3, center=0,\n",
    "            square=True, linewidths=.5, cbar_kws={\"shrink\": .5}, annot=False);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<a id=\"fe_scatter\"></a>\n",
    "#### Scatter Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def sample_scatter(title, x, xLabel, y, yLabel, sampleSize):\n",
    "    \n",
    "    pylab.rcParams['figure.figsize'] = (8, 8)\n",
    "\n",
    "    # Grab sample\n",
    "    query = \"\"\"\n",
    "        SELECT count(*) AS n\n",
    "        FROM public.model_inputs;\n",
    "    \"\"\".format(\",\".join(contFeatureNames))\n",
    "    cur.execute(query)\n",
    "\n",
    "    colnames = [desc[0] for desc in cur.description]\n",
    "    n = pd.DataFrame(cur.fetchall(), columns=colnames)['n'][0]\n",
    "    limit = math.floor(n * sampleSize)\n",
    "    \n",
    "    query = \"\"\"\n",
    "        SELECT {} AS col1\n",
    "              ,{} AS col2\n",
    "        FROM public.model_inputs\n",
    "        LIMIT {};\n",
    "    \"\"\".format(x, y, limit)\n",
    "    cur.execute(query)\n",
    "\n",
    "    colnames = [desc[0] for desc in cur.description]\n",
    "    sample = pd.DataFrame(cur.fetchall(), columns=colnames)    \n",
    "    \n",
    "    # Generate scatterplot\n",
    "    if x == y:\n",
    "        sample\n",
    "    plt = sns.regplot(x=\"col1\", y=\"col2\", data=sample)\n",
    "    \n",
    "    # titles\n",
    "    plt.set_title(\"\\n\".join(tw.wrap(title,50)),fontsize=16)\n",
    "    plt.set_xlabel(xLabel,fontsize=16)\n",
    "    plt.set_ylabel(yLabel,fontsize=16)\n",
    "\n",
    "    # add 1000s commas\n",
    "    plt.get_yaxis().set_major_formatter(\n",
    "        matplotlib.ticker.FuncFormatter(lambda y, p: format(int(y), ',')))\n",
    "    plt.get_xaxis().set_major_formatter(\n",
    "        matplotlib.ticker.FuncFormatter(lambda y, p: format(int(y), ',')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "x = contFeatureNames[0]\n",
    "y = contFeatureNames[1]\n",
    "\n",
    "def reset():\n",
    "    ipd.clear_output()\n",
    "    printmd(\"-----\\n **Select Features:**\")\n",
    "    ipd.display(scatterDropdown1, scatterDropdown2)\n",
    "\n",
    "    sample_scatter(\"{} by {}\".format(x, y), x, x, y, y, 1)   \n",
    "    \n",
    "def os1(res):\n",
    "    global x\n",
    "    if res['type'] == 'change' and res['name'] == 'value':\n",
    "        contFeatureNames.append(x)\n",
    "        x = res['new']\n",
    "        contFeatureNames.remove(x)\n",
    "        reset()\n",
    "\n",
    "def os2(res):\n",
    "    global y\n",
    "    if res['type'] == 'change' and res['name'] == 'value':\n",
    "        y = res['new']\n",
    "        reset()\n",
    "                   \n",
    "scatterDropdown1 = widgets.Dropdown(\n",
    "    options=contFeatureNames,\n",
    "    value=x,\n",
    "    description='x:',\n",
    "    disabled=False,\n",
    ")\n",
    "\n",
    "scatterDropdown2 = widgets.Dropdown(\n",
    "    options=contFeatureNames,\n",
    "    value=y,\n",
    "    description='y:',\n",
    "    disabled=False,\n",
    ")\n",
    "\n",
    "scatterDropdown1.observe(os1)\n",
    "scatterDropdown2.observe(os2)\n",
    "\n",
    "reset()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<a id=\"tag\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### (OLD NOTEBOOK) Training & Validation Sample Split\n",
    "<a id=\"train_vali_split\"></a>\n",
    "https://madlib.apache.org/docs/latest/group__grp__train__test__split.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# split training and validation set\n",
    "# we are careful not to include the same customer in both sets\n",
    "query = \"\"\"\n",
    "    DROP TABLE IF EXISTS public.model\n",
    "                        ,public.model_train\n",
    "                        ,public.model_test;\n",
    "                        \n",
    "    SELECT madlib.train_test_split(\n",
    "        'public.model_inputs',\n",
    "        'public.model',\n",
    "        0.7,\n",
    "        NULL,\n",
    "        NULL,\n",
    "        '*',\n",
    "        FALSE,\n",
    "        TRUE\n",
    "    )\n",
    "\"\"\"\n",
    "cur.execute(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "    SELECT *\n",
    "    FROM public.model_train\n",
    "    LIMIT 5\n",
    "\"\"\"\n",
    "df = query_gpdb(query)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest (MADlib)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run #1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql SET search_path=network_anomaly_run1,madlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "DROP TABLE IF EXISTS training_data_sample1;\n",
    "SELECT madlib.balance_sample(\n",
    "                              'public.training_data',             -- Source table\n",
    "                              'training_data_sample1',      -- Output table\n",
    "                              'y',           -- Class column\n",
    "                              'uniform',           -- Uniform sample\n",
    "                               2300);                -- Desired output table size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql ALTER TABLE training_data_sample1 DROP COLUMN __madlib_id__;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run #2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql SET search_path=network_anomaly_run2,madlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql \n",
    "DROP TABLE IF EXISTS y;\n",
    "CREATE TABLE y AS SELECT y, (COUNT(*)>=1000) AS is_top FROM public.training_data GROUP BY y;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql DROP TABLE IF EXISTS training_data_top;\n",
    "CREATE TABLE training_data_top AS\n",
    "    SELECT *\n",
    "FROM public.training_data JOIN y USING(y) WHERE is_top=TRUE;\n",
    "SELECT COUNT(*) FROM training_data_top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql DROP TABLE IF EXISTS training_data_bottom;\n",
    "CREATE TABLE training_data_bottom AS\n",
    "    SELECT *\n",
    "FROM public.training_data JOIN y USING(y) WHERE is_top=FALSE;\n",
    "SELECT COUNT(*) FROM training_data_bottom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "DROP TABLE IF EXISTS training_data_top_sample2;\n",
    "SELECT madlib.balance_sample(\n",
    "                              'training_data_top',              -- Source table\n",
    "                              'training_data_top_sample2',      -- Output table\n",
    "                              'y',                 -- Class column\n",
    "                              'uniform',           -- Uniform sample\n",
    "                               9000);              -- Desired output table size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql SELECT y, COUNT(*) FROM training_data_top_sample2 GROUP BY y;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "DROP TABLE IF EXISTS training_data_bottom_sample2;\n",
    "SELECT madlib.balance_sample(\n",
    "                              'training_data_bottom',              -- Source table\n",
    "                              'training_data_bottom_sample2',      -- Output table\n",
    "                              'y',                 -- Class column\n",
    "                              'uniform',           -- Uniform sample\n",
    "                               1400);              -- Desired output table size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql SELECT y, COUNT(*) FROM training_data_bottom_sample2 GROUP BY y;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "    DROP TABLE IF EXISTS training_data_balanced2;\n",
    "    CREATE TABLE training_data_balanced2 AS\n",
    "    SELECT * FROM training_data_top_sample2 UNION SELECT * FROM training_data_bottom_sample2;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql SELECT y,count(*) FROM training_data_balanced2 GROUP BY y ORDER BY 2;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql ALTER TABLE training_data_balanced2 DROP COLUMN is_top;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "DROP TABLE IF EXISTS balanced2_train, balanced2_test;\n",
    "SELECT madlib.train_test_split(\n",
    "                                'training_data_balanced2',    -- Source table\n",
    "                                'balanced2',            -- Output table\n",
    "                                0.8,       -- Sample proportion\n",
    "                                NULL,       -- Sample proportion\n",
    "                                NULL,       -- Strata definition\n",
    "                                NULL,       -- Columns to output\n",
    "                                FALSE,     -- Sample without replacement\n",
    "                                TRUE);    -- Do not separate output tables\n",
    "SELECT y,COUNT(*) FROM balanced2_train GROUP BY y;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"#tag\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql SELECT y,COUNT(*) FROM balanced2_test GROUP BY y;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run #3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql SET search_path=network_anomaly_run3,madlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "DROP TABLE IF EXISTS training_data_sample3;\n",
    "SELECT madlib.balance_sample(\n",
    "                              'public.training_data',             -- Source table\n",
    "                              'training_data_sample3',      -- Output table\n",
    "                              'y',           -- Class column\n",
    "                              'uniform',           -- Uniform sample\n",
    "                               230000);                -- Desired output table size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql ALTER TABLE training_data_sample3 DROP COLUMN __madlib_id__;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "DROP TABLE IF EXISTS balanced3_train, balanced3_test;\n",
    "SELECT madlib.train_test_split(\n",
    "                                'training_data_sample3',    -- Source table\n",
    "                                'balanced3',            -- Output table\n",
    "                                0.8,       -- Sample proportion\n",
    "                                NULL,       -- Sample proportion\n",
    "                                NULL,       -- Strata definition\n",
    "                                NULL,       -- Columns to output\n",
    "                                FALSE,     -- Sample without replacement\n",
    "                                TRUE);    -- Separate output tables\n",
    "SELECT y,COUNT(*) FROM balanced3_train GROUP BY y;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "SELECT y,COUNT(*) FROM balanced3_test GROUP BY y;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run #4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "DROP TABLE IF EXISTS training_data_sample4;\n",
    "SELECT madlib.balance_sample(\n",
    "                              'public.training_data',             -- Source table\n",
    "                              'training_data_sample4',      -- Output table\n",
    "                              'y',           -- Class column\n",
    "                               $$\n",
    "                               class19=10, class12=10, class13=10, \n",
    "                               class09=20, class03=20, class08=20, class16=20, class05=20, \n",
    "                               class22=100, class07=100, class02=100, class04=100,\n",
    "                               class14=1000, \n",
    "                               class20=5000, class21=5000, class01=5000, class11=5000, \n",
    "                               class15=20000, class06=20000, class17=20000,\n",
    "                               normal=100000, class10=100000, class18=100000\n",
    "                               $$);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql ALTER TABLE training_data_sample4 DROP COLUMN __madlib_id__;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "DROP TABLE IF EXISTS balanced4_train, balanced4_test;\n",
    "SELECT madlib.train_test_split(\n",
    "                                'training_data_sample4',    -- Source table\n",
    "                                'balanced4',            -- Output table\n",
    "                                0.8,       -- Sample proportion\n",
    "                                NULL,       -- Sample proportion\n",
    "                                NULL,       -- Strata definition\n",
    "                                NULL,       -- Columns to output\n",
    "                                FALSE,     -- Sample without replacement\n",
    "                                TRUE);    -- Separate output tables\n",
    "SELECT y,COUNT(*) FROM balanced4_train GROUP BY y;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "SELECT y,COUNT(*) FROM balanced4_test GROUP BY y;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model\n",
    "<a id=\"rf_train_model\"></a>\n",
    "https://madlib.apache.org/docs/latest/group__grp__random__forest.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql ALTER TABLE balanced2_train DROP COLUMN __madlib_id__;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql ALTER TABLE balanced2_test DROP COLUMN __madlib_id__;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "DROP TABLE IF EXISTS rf_model4, rf_model4_summary, rf_model4_group;\n",
    "SELECT madlib.forest_train(\n",
    "            'training_data_sample4',  -- source table\n",
    "            'rf_model4',              -- output table\n",
    "            'id',                     -- unique row id\n",
    "            'y',                      -- dependent var\n",
    "            '*',                      -- indep var\n",
    "            null,                     -- cols to exclude\n",
    "            null,                     -- grouping\n",
    "            10::integer,              -- num trees\n",
    "            5::integer,               -- num random features\n",
    "            true::boolean,            -- importance\n",
    "            5::integer,               -- num permutations\n",
    "            10::integer,              -- max tree depth\n",
    "            3::integer,               -- min split\n",
    "            1::integer,               -- min bucket\n",
    "            10::integer,               -- num splits\n",
    "            NULL,                     -- null handling\n",
    "            TRUE                      -- verbose\n",
    "        );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "    SELECT gid, sample_id\n",
    "    FROM rf_model4;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"rf_variable_importance\"></a>\n",
    "#### Variable Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"SET search_path=public, madlib;\n",
    "    SELECT unnest(string_to_array(independent_varnames,',')) AS feature_name\n",
    "          ,unnest(impurity_var_importance) AS impurity_feature_importance\n",
    "          ,unnest(oob_var_importance) AS oob_feature_importance\n",
    "    FROM rf_model4_group l\n",
    "        ,rf_model4_summary r\n",
    "    ORDER BY 2 DESC\n",
    "\"\"\"\n",
    "\n",
    "df = query_gpdb(query)\n",
    "ipd.display(df.head(10))\n",
    "bar_plot(df,\"Feature Importance\",\"feature_name\",'Feature Name',\"impurity_feature_importance\",\"Feature Importance\", \"#4378E2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bar_plot(df,\"Feature Importance\",\"feature_name\",'Feature Name',\"oob_feature_importance\",\"Feature Importance\", \"#4378E2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "DROP TABLE IF EXISTS feature_importance;\n",
    "SELECT get_var_importance('rf_model4', 'feature_importance');\n",
    "SELECT * FROM feature_importance ORDER BY impurity_var_importance DESC;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"rf_score_out_of_sample\"></a>\n",
    "#### Score Validation/Training Data\n",
    "\n",
    "https://madlib.apache.org/docs/latest/group__grp__random__forest.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate validation dataset\n",
    "query = \"\"\"\n",
    "    DROP TABLE IF EXISTS rf_model4_scored;\n",
    "    SELECT madlib.forest_predict('rf_model4',\n",
    "                                 'balanced4_test',\n",
    "                                 'rf_model4_scored',\n",
    "                                 'response');\n",
    "                \n",
    "    DROP TABLE IF EXISTS rf_model4_scored_tmp;\n",
    "    CREATE TABLE rf_model4_scored_tmp AS\n",
    "    SELECT *\n",
    "    FROM rf_model4_scored\n",
    "    JOIN balanced4_test\n",
    "    USING (id);\n",
    "    DROP TABLE rf_model4_scored;\n",
    "    ALTER TABLE rf_model4_scored_tmp RENAME TO rf_model4_scored;\n",
    "    SELECT * FROM rf_model4_scored LIMIT 10;\n",
    "    \n",
    "\"\"\"\n",
    "cur.execute(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate training dataset\n",
    "query = \"\"\"\n",
    "    DROP TABLE IF EXISTS rf_model4_scored;\n",
    "    SELECT madlib.forest_predict('rf_model4',\n",
    "                                 'balanced4_train',\n",
    "                                 'rf_model4_scored',\n",
    "                                 'response');\n",
    "                \n",
    "    DROP TABLE IF EXISTS rf_model4_scored_tmp;\n",
    "    CREATE TABLE rf_model4_scored_tmp AS\n",
    "    SELECT *\n",
    "    FROM rf_model4_scored\n",
    "    JOIN balanced4_train\n",
    "    USING (id);\n",
    "    DROP TABLE rf_model4_scored;\n",
    "    ALTER TABLE rf_model4_scored_tmp RENAME TO rf_model4_scored;\n",
    "    SELECT * FROM rf_model4_scored LIMIT 10;\n",
    "    \n",
    "\"\"\"\n",
    "cur.execute(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on entire 4.9-million \"training\" dataset\n",
    "query = \"\"\"\n",
    "    DROP TABLE IF EXISTS rf_model1_scored;\n",
    "    SELECT madlib.forest_predict('rf_model1',\n",
    "                                 'public.training_data',\n",
    "                                 'rf_model1_scored',\n",
    "                                 'response');\n",
    "                \n",
    "    DROP TABLE IF EXISTS rf_model1_scored_tmp;\n",
    "    CREATE TABLE rf_model1_scored_tmp AS\n",
    "    SELECT *\n",
    "    FROM rf_model1_scored\n",
    "    JOIN public.training_data\n",
    "    USING (id);\n",
    "    DROP TABLE rf_model1_scored;\n",
    "    ALTER TABLE rf_model1_scored_tmp RENAME TO rf_model1_scored;\n",
    "    SELECT * FROM rf_model1_scored LIMIT 10;\n",
    "    \n",
    "\"\"\"\n",
    "cur.execute(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on 311K \"eval\" dataset\n",
    "query = \"\"\"\n",
    "    DROP TABLE IF EXISTS rf_model1_scored;\n",
    "    SELECT madlib.forest_predict('rf_model1',\n",
    "                                 'public.eval_data',\n",
    "                                 'rf_model1_scored',\n",
    "                                 'response');\n",
    "                \n",
    "    DROP TABLE IF EXISTS rf_model1_scored_tmp;\n",
    "    CREATE TABLE rf_model1_scored_tmp AS\n",
    "    SELECT *\n",
    "    FROM rf_model1_scored\n",
    "    JOIN public.eval_data\n",
    "    USING (id);\n",
    "    DROP TABLE rf_model1_scored;\n",
    "    ALTER TABLE rf_model1_scored_tmp RENAME TO rf_model1_scored;\n",
    "    SELECT * FROM rf_model1_scored LIMIT 10;\n",
    "    \n",
    "\"\"\"\n",
    "cur.execute(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "select * from rf_model2_scored order by id limit 10;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql \n",
    "SET search_path=network_anomaly_run2, madlib;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "DROP TABLE IF EXISTS confusion;\n",
    "SELECT madlib.confusion_matrix( 'rf_model4_scored', 'confusion', 'estimated_y', 'y');\n",
    "SELECT * FROM confusion ORDER BY \"class\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql DROP TABLE IF EXISTS accuracy_by_class;\n",
    "CREATE TABLE accuracy_by_class AS\n",
    "    SELECT y,correct, total,correct::FLOAT/total as accuracy\n",
    "FROM (SELECT y, COUNT(*) AS correct FROM rf_model4_scored WHERE y=estimated_y GROUP BY y) c JOIN\n",
    "     (SELECT y,count(*) AS total FROM rf_model4_scored GROUP BY y) t USING(y);\n",
    "SELECT * FROM accuracy_by_class ORDER BY y;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql SELECT AVG(accuracy) AS balanced_accuracy FROM accuracy_by_class;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build histogram by class if don't have label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "select estimated_y, count(*) from rf_model3_scored group by estimated_y order by estimated_y;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Rest of OLD NOTEBOOK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<a id=\"rf_auc\"></a>\n",
    "#### Area Under ROC Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# auc\n",
    "query = \"\"\"\n",
    "    DROP TABLE IF EXISTS public.model_test_scored_auc;\n",
    "    SELECT madlib.area_under_roc(\n",
    "        'public.model_test_scored'\n",
    "       ,'public.model_test_scored_auc'\n",
    "       ,'estimated_prob_1'\n",
    "       ,'approval'\n",
    "    )\n",
    "\"\"\"\n",
    "cur.execute(query)\n",
    "\n",
    "query = \"\"\"\n",
    "    SELECT * \n",
    "    FROM public.model_test_scored_auc;\n",
    "\"\"\"\n",
    "auc = query_gpdb(query)['area_under_roc'][0]\n",
    "\n",
    "message = \"\"\"-----\\n **AUC =** {:0.5f}\"\"\".format(auc)\n",
    "printmd(message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<a id=\"rf_roc\"></a>\n",
    "#### Receiver Operating Characteristic Graph (ROC Curve)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# roc\n",
    "query = \"\"\"\n",
    "    DROP TABLE IF EXISTS public.model_test_scored_roc;\n",
    "    SELECT madlib.binary_classifier( \n",
    "        'public.model_test_scored'\n",
    "       ,'public.model_test_scored_roc'\n",
    "       ,'estimated_prob_1'\n",
    "       ,'approval'\n",
    "    );\n",
    "\"\"\"\n",
    "cur.execute(query)\n",
    "\n",
    "query = \"\"\"\n",
    "    SELECT threshold\n",
    "          ,fpr\n",
    "          ,tpr\n",
    "    FROM public.model_test_scored_roc\n",
    "    ORDER BY 1\n",
    "\"\"\"\n",
    "df = query_gpdb(query)\n",
    "\n",
    "# roc curve\n",
    "pylab.rcParams['figure.figsize'] = (8, 8)\n",
    "\n",
    "plt.figure()\n",
    "lw = 2\n",
    "plt.plot(df['fpr'], df['tpr'], color='darkgreen', lw=lw, label='AUC {:0.2f}'.format(auc))\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<a id=\"rf_confusion_matrix\"></a>\n",
    "#### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# confusion matrix (inclusive)\n",
    "cutoff = 0.5\n",
    "\n",
    "query = \"\"\"\n",
    "        SELECT approval AS obs\n",
    "              ,CASE WHEN estimated_prob_1 >= {} THEN 1 ELSE 0 END AS pred\n",
    "              ,count(*) AS num\n",
    "        FROM public.model_test_scored\n",
    "        GROUP BY 1,2\n",
    "        ORDER BY 1,2\n",
    "    \"\"\".format(cutoff)\n",
    "\n",
    "query_gpdb(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<a id=\"rf_model_storage\"></a>\n",
    "#### Model Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "        DROP TABLE IF EXISTS public.my_models;\n",
    "        CREATE TABLE public.my_models (\n",
    "            gid integer[]\n",
    "           ,sample_id integer[]\n",
    "           ,tree madlib.bytea8[]\n",
    "           ,created timestamp\n",
    "           ,team text\n",
    "           ,owner text\n",
    "           ,description text\n",
    "           ,model_type text\n",
    "           ,model_params text\n",
    "           ,current boolean\n",
    "           ,model_id serial\n",
    "        );\n",
    "        \n",
    "        INSERT INTO public.my_models (\n",
    "            SELECT array_agg(gid) AS gid\n",
    "                  ,array_agg(sample_id) AS sample_id\n",
    "                  ,array_agg(tree) AS tree\n",
    "                  ,now() AS created\n",
    "                  ,'Pivotal Data Science Atlanta' AS team\n",
    "                  ,'Jarrod Vawdrey' AS owner\n",
    "                  ,'This is an example credit scoring model' AS description\n",
    "                  ,'MADlib random forest' AS model_type\n",
    "                  ,'{num_trees= ,num_random_features= ,importance= ,num_permutations= ,max_tree_depth= ,min_split= ,min_bucket= ,num_splits= }' AS model_params\n",
    "                  ,True AS current\n",
    "            FROM public.rf_model_output   \n",
    "        );\n",
    "        \n",
    "        SELECT gid\n",
    "              ,sample_id\n",
    "              ,created\n",
    "              ,team\n",
    "              ,owner\n",
    "              ,description\n",
    "              ,model_type\n",
    "              ,model_params\n",
    "              ,current\n",
    "        FROM public.my_models\n",
    "    \"\"\"\n",
    "\n",
    "query_gpdb(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Model Scoring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<a id=\"model_scoring_Example\"></a>\n",
    "#### Model Scoring Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "<a id=\"rf_train_model\"></a>\n",
    "featureNames = ['a2', 'a3', 'a8', 'a11', 'a14', 'a15', 'a1_a', 'a4_l', 'a4_u', 'a5_g', 'a5_gg', 'a6_aa', 'a6_c', 'a6_cc', 'a6_d', 'a6_e', 'a6_ff', 'a6_i', 'a6_j', 'a6_k', 'a6_m', 'a6_q', 'a6_r', 'a6_w', 'a7_bb', 'a7_dd', 'a7_ff', 'a7_h', 'a7_j', 'a7_n', 'a7_o', 'a7_v', 'a9_true', 'a10_true', 'a12_true', 'a13_g', 'a13_p']\n",
    "    \n",
    "\n",
    "def add_continuous_slider(n, default):\n",
    "    tstr = \"target_column == '{}'\".format(n)\n",
    "    minValue = math.floor(data_summary.query(tstr)['min'])\n",
    "    minValueOrZero = min(0,float(minValue))\n",
    "    maxValue = math.ceil(data_summary.query(tstr)['max'])\n",
    "    return widgets.FloatSlider(\n",
    "        value=default,\n",
    "        min=minValueOrZero,\n",
    "        max=maxValue,\n",
    "        step=0.1,\n",
    "        description=\"\",\n",
    "        disabled=False,\n",
    "        continuous_update=False,\n",
    "        orientation='horizontal',\n",
    "        readout=True,\n",
    "        readout_format='.1f',\n",
    "    )\n",
    "\n",
    "def add_drop_down(n, default):\n",
    "    \n",
    "    query = \"\"\"\n",
    "        SELECT {} AS col\n",
    "        FROM public.credit_application_data\n",
    "        GROUP BY 1\n",
    "        ORDER BY 1\n",
    "    \"\"\".format(n)\n",
    "    values = query_gpdb(query)['col']\n",
    "\n",
    "    return widgets.Dropdown(\n",
    "        options=values,\n",
    "        value=default,\n",
    "        description='',\n",
    "        disabled=False,\n",
    "    )\n",
    "\n",
    "def add_widgets():\n",
    "    \n",
    "    message = \"### Loan Application \\n ------\"\n",
    "    printmd(message)\n",
    "    \n",
    "    myWidgets = []\n",
    "\n",
    "    myWidgets.append({'a1':add_drop_down('a1','a')})\n",
    "    myWidgets.append({'a2':add_continuous_slider('a2',35.43)})\n",
    "    myWidgets.append({'a3':add_continuous_slider('a3',12.0)})\n",
    "    myWidgets.append({'a4':add_drop_down('a4','u')})\n",
    "    myWidgets.append({'a5':add_drop_down('a5','g')})\n",
    "    myWidgets.append({'a6':add_drop_down('a6','q')})\n",
    "    myWidgets.append({'a7':add_drop_down('a7','h')})\n",
    "    myWidgets.append({'a8':add_continuous_slider('a8',14.0)})\n",
    "    myWidgets.append({'a9':add_drop_down('a9',True)})\n",
    "    myWidgets.append({'a10':add_drop_down('a10',True)})\n",
    "    myWidgets.append({'a11':add_continuous_slider('a11',8.0)})\n",
    "    myWidgets.append({'a12':add_drop_down('a12',False)})\n",
    "    myWidgets.append({'a13':add_drop_down('a13','g')})\n",
    "    myWidgets.append({'a14':add_continuous_slider('a14',0.0)})\n",
    "    myWidgets.append({'a15':add_continuous_slider('a15',6590.0)})\n",
    "    \n",
    "    for widget in myWidgets:\n",
    "        n = widget.keys()[0]\n",
    "        printmd(\"**{}:**\".format(n))\n",
    "        ipd.display(widget[n])\n",
    "\n",
    "    message = \"------\"\n",
    "    printmd(message)\n",
    "    \n",
    "    return myWidgets\n",
    "\n",
    "    \n",
    "def create_model_input(myWidgets):\n",
    "\n",
    "    checks = {}\n",
    "    conts = []\n",
    "    f = []\n",
    "    \n",
    "    for i in range(0,len(featureNames)):\n",
    "        f.append(0.0)\n",
    "    \n",
    "    for feature in featureNames:\n",
    "        if \"_\" in feature:\n",
    "            key = feature[0:feature.find(\"_\")]\n",
    "            val = feature[feature.find(\"_\")+1:len(feature)]\n",
    "            if key in checks:\n",
    "                checks[key].append(val)\n",
    "            else:\n",
    "                checks[key] = [val]\n",
    "        else:\n",
    "            conts.append(feature)\n",
    "            \n",
    "    for widget in myWidgets:\n",
    "        n = widget.keys()[0]\n",
    "        val = widget[n].value\n",
    "\n",
    "        # lower case boolean strings\n",
    "        if isinstance(val,np.bool_):\n",
    "            val = str(val).lower()\n",
    "\n",
    "        if n in checks:\n",
    "            checkFlag = False\n",
    "            for c in checks[n]:\n",
    "                if c == val:\n",
    "                    checkFlag = True\n",
    "                    pos = featureNames.index(\"{}_{}\".format(n,val))\n",
    "                    f[pos] = 1.0   \n",
    "                    \n",
    "            # make all associated values 0\n",
    "            if checkFlag == False:\n",
    "                for feature in featureNames:\n",
    "                    if \"_\" in feature and feature[0:feature.find(\"_\")+1] == n:\n",
    "                        pos = featureNames.index(feature)\n",
    "                        f[pos] = 0.0   \n",
    "        elif n in conts:\n",
    "            pos = featureNames.index(n)\n",
    "            f[pos] = val\n",
    "\n",
    "    return f\n",
    "        \n",
    "def rf_score(modelInputs):\n",
    "    \n",
    "    print(modelInputs)\n",
    "    print(featureNames)\n",
    "    \n",
    "    ddlString = \"_id integer\"\n",
    "    for f in featureNames:\n",
    "        ddlString = ddlString + \",{} float\".format(f)\n",
    "\n",
    "    query = \"\"\"\n",
    "        DROP TABLE IF EXISTS public.prod_example_data, public.prod_example_score;\n",
    "        CREATE TABLE public.prod_example_data ({});\n",
    "        INSERT INTO public.prod_example_data VALUES ({});\n",
    "        DROP TABLE IF EXISTS public.model_test_scored_tmp;\n",
    "        SELECT madlib.forest_predict('public.rf_model_output',\n",
    "                                     'public.prod_example_data',\n",
    "                                     'public.prod_example_score',\n",
    "                                     'prob');\n",
    "        SELECT * FROM public.prod_example_score;\n",
    "    \"\"\".format(ddlString, \",\".join(str(x) for x in modelInputs))\n",
    "\n",
    "    score = float(query_gpdb(query)['estimated_prob_1'])\n",
    "    \n",
    "    message = \"High\"\n",
    "    if score <= 0.5:\n",
    "        message = \"Low\"\n",
    "    elif score <= 0.75:\n",
    "        message = \"Average\"\n",
    "    \n",
    "    return (score, message)\n",
    "    \n",
    "def on_appbutton_click(b):\n",
    "    \n",
    "    ipd.clear_output()\n",
    "    \n",
    "    message = \"### Loan Approval Results \\n------\\n\"\n",
    "    printmd(message)\n",
    "    \n",
    "    modelInput = create_model_input(myWidgets)\n",
    "    \n",
    "    s, m = rf_score(modelInput)\n",
    "    \n",
    "    message = \"**Approval Score:** {}\".format(s)\n",
    "    printmd(message)\n",
    "    \n",
    "    message = \"*Your chances of being approved are '{}'*\".format(m)\n",
    "    printmd(message)\n",
    "    \n",
    "    cleanModelInputs = \"\"\n",
    "    for i in range(0,len(featureNames)):\n",
    "        cleanModelInputs = cleanModelInputs + \"{} = {}\\n\\n\".format(featureNames[i],modelInput[i])\n",
    "\n",
    "    message = \"**Model Inputs:** \\n\\n{}\".format(cleanModelInputs)\n",
    "    printmd(message)\n",
    "    \n",
    "    printmd(\"\\n------\")\n",
    "    \n",
    "myWidgets = add_widgets()\n",
    "appbutton = widgets.Button(description=\"Calculate Approval\")\n",
    "ipd.display(appbutton)\n",
    "appbutton.on_click(on_appbutton_click)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
