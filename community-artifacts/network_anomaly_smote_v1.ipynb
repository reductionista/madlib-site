{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network anomaly detection\n",
    "* <a href=\"#tag\">Tag</a>\n",
    "\n",
    "Using network data build a multiclass classification model to predict anomolies\n",
    "\n",
    "- Jan 2021\n",
    "- Domino Valdano and Frank McQuillan\n",
    "\n",
    "\n",
    "## Index\n",
    "\n",
    "### Setup \n",
    "\n",
    "* <a href=\"#dependencies\">Dependencies</a>\n",
    "* <a href=\"#package_options\">Package Options</a>\n",
    "* <a href=\"#database_connection\">Database Connection</a>\n",
    "    \n",
    "    \n",
    "### Data Loading\n",
    "\n",
    "* <a href=\"#external_table\">External Table Definition</a>\n",
    "* <a href=\"#download_data\">Download Data and View Sample</a>\n",
    "\n",
    "\n",
    "### Data Audit\n",
    "\n",
    "* <a href=\"#summary_statistics\">Summary Statistics</a>\n",
    "\n",
    "\n",
    "### Data Exploration\n",
    "\n",
    "* <a href=\"#de_categorical\">Categorical Columns</a>\n",
    "* <a href=\"#de_continuous\">Continuous Columns</a>\n",
    "\n",
    "\n",
    "### Feature Engineering\n",
    "\n",
    "* <a href=\"#fe_continuous\">Continuous Features</a>\n",
    "* <a href=\"#fe_one_hot\">One Hot Encode Categorical Features</a>\n",
    "* <a href=\"#fe_combine\">Combine Continuous & Categorical Features</a>\n",
    "* <a href=\"#fe_cats_dep\">Plot Categorical Features By Response</a>\n",
    "* <a href=\"#fe_chi_sq\">Chi-squared Testing</a>\n",
    "* <a href=\"#fe_corr\">Correlation Testing</a>\n",
    "* <a href=\"#fe_scatter\">Scatter Plots</a>\n",
    "\n",
    "\n",
    "### Model Development\n",
    "\n",
    "* <a href=\"#train_vali_split\">Training & Validation Sample Split</a>\n",
    "\n",
    "\n",
    "* **Random Forest (MADlib)**\n",
    "    * <a href=\"#rf_train_model\">Train model</a>\n",
    "    * <a href=\"#rf_variable_importance\">Variable Importance</a>\n",
    "    * <a href=\"#rf_score_out_of_sample\">Score Validation Data</a>\n",
    "    * <a href=\"#rf_auc\">Area Under ROC Curve</a>\n",
    "    * <a href=\"#rf_roc\">Receiver Operating Characteristic Graph (ROC Curve)</a>\n",
    "    * <a href=\"#rf_confusion_matrix\">Confusion Matrix</a>\n",
    "    * <a href=\"#rf_model_storage\">Model Storage</a>\n",
    "\n",
    "### Model Scoring\n",
    "\n",
    "\n",
    "* <a href=\"#model_scoring_Example\">Model Scoring Example</a>\n",
    "\n",
    "----\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"dependencies\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Greenplum Database 5.x on GCP (PM demo machine) - no tunnel (just Jupyter client 8888 tunnel)\n",
    "%sql postgresql://gpadmin@localhost:5432/madlib\n",
    "        \n",
    "# PostgreSQL local\n",
    "#%sql postgresql://fmcquillan@localhost:5432/madlib\n",
    "%config SqlMagic.autopandas=True\n",
    "%config SqlMagic.short_errors=False\n",
    "#%config SqlMagic.column_local_vars=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dependencies\n",
    "import psycopg2               # Python-PostgreSQL Database Adapter - https://pypi.python.org/pypi/psycopg2\n",
    "import pandas as pd           # Python Data Analysis Library - https://pandas.pydata.org/\n",
    "import seaborn as sns         # Statistical data visualization - https://seaborn.pydata.org/\n",
    "import math                   # Mathematical functions - https://docs.python.org/2/library/math.html\n",
    "import textwrap as tw         # Text wrapping and filling - https://docs.python.org/2/library/textwrap.html\n",
    "import ipywidgets as widgets  # Jupyter Widgets - https://ipywidgets.readthedocs.io/en/latest/\n",
    "import IPython.display as ipd # http://ipython.org/documentation.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"package_options\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "# package options\n",
    "# %matplotlib inline\n",
    "%pylab inline\n",
    "\n",
    "pylab.rcParams['figure.figsize'] = (12, 8)\n",
    "    \n",
    "pd.options.mode.chained_assignment = None \n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "\n",
    "pd.options.display.max_rows = 10000\n",
    "pd.options.display.max_columns = 10000\n",
    "\n",
    "sns.set(style=\"darkgrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"database_connection\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### Connection Details \n",
       " ------"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Host:**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfd53218890e467492842f884da8909d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value=u'')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Port:**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1996a350c85b4848807038d595b5a6e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value=u'')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Database Name:**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cecd567074ce40ffa0bb18a938f17776",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value=u'')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Username:**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8cf9a6138f064a29b371fc7eea6c2bb4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value=u'')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Password:**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "062fda583b7e479b866162c1882f7acb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value=u'')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "*Leave blank for default values*"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27610f64987b4f438e7656c321f7b474",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description=u'Connect', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# init to default values\n",
    "database_host = 'localhost'\n",
    "database_databasename = 'madlib'\n",
    "database_username = 'gpadmin'\n",
    "database_password = ''\n",
    "database_port = '8000'\n",
    "\n",
    "# interpret string as markdown\n",
    "def printmd(string):\n",
    "    ipd.display(ipd.Markdown(string))\n",
    "    \n",
    "# forms\n",
    "message = \"### Connection Details \\n ------\"\n",
    "printmd(message)\n",
    "    \n",
    "printmd(\"**Host:**\")\n",
    "inputHost = widgets.Text()\n",
    "ipd.display(inputHost)\n",
    "\n",
    "printmd(\"**Port:**\")\n",
    "inputPort = widgets.Text()\n",
    "ipd.display(inputPort)\n",
    "\n",
    "printmd(\"**Database Name:**\")\n",
    "inputDatabaseName = widgets.Text()\n",
    "ipd.display(inputDatabaseName)\n",
    "\n",
    "printmd(\"**Username:**\")\n",
    "inputUsername = widgets.Text()\n",
    "ipd.display(inputUsername)\n",
    "\n",
    "printmd(\"**Password:**\")\n",
    "inputPassword = widgets.Text()\n",
    "ipd.display(inputPassword)\n",
    "\n",
    "printmd(\"*Leave blank for default values*\")\n",
    "\n",
    "\n",
    "def db_connect():\n",
    "    global conn, cur\n",
    "    try:\n",
    "        connString = \"host='{}' dbname='{}' user='{}' password='{}' port={}\".format(database_host,database_databasename,database_username,database_password,database_port)\n",
    "        # print connString\n",
    "        conn = psycopg2.connect(connString)\n",
    "        cur = conn.cursor()\n",
    "        conn.autocommit = True\n",
    "        message = \"<span style='color:green'>**Connection successful!**</span>\"\n",
    "        printmd(message)\n",
    "    except:\n",
    "        message = \"<span style='color:red'>**ERROR: Unable to connect to the database**</span>\"\n",
    "        printmd(message)\n",
    "    \n",
    "def on_button_click(b):\n",
    "    \n",
    "    global database_host, database_databasename, database_username, database_password, database_port\n",
    "    \n",
    "    ipd.clear_output()\n",
    "    \n",
    "    message = \"### Connection Details \\n ------\"\n",
    "    printmd(message)\n",
    "    \n",
    "    if inputHost.value == \"\":\n",
    "        message = \"**Host:** {} (default)\".format(database_host)\n",
    "        printmd(message)\n",
    "    else:\n",
    "        database_host = inputHost.value\n",
    "        message = \"**Host:** {}\".format(database_host)\n",
    "        printmd(message)\n",
    "\n",
    "    if inputPort.value == \"\":\n",
    "        message = \"**Port:** {} (default)\".format(database_port)\n",
    "        printmd(message)\n",
    "    else:\n",
    "        database_port = inputPort.value\n",
    "        message = \"**Port:** {}\".format(database_port)\n",
    "        printmd(message)\n",
    "        \n",
    "    if inputDatabaseName.value == \"\":\n",
    "        message = \"**Database name:** {} (default)\".format(database_databasename)\n",
    "        printmd(message)\n",
    "    else:\n",
    "        database_databasename = inputDatabaseName.value\n",
    "        message = \"**Database name:** {}\".format(database_databasename)\n",
    "        printmd(message)\n",
    "        \n",
    "    if inputUsername.value == \"\":\n",
    "        message = \"**Username:** {} (default)\".format(database_username)\n",
    "        printmd(message)\n",
    "    else:\n",
    "        database_username = inputUsername.value\n",
    "        message = \"**Username:** {}\".format(database_username)\n",
    "        printmd(message)\n",
    "        \n",
    "    if inputPassword.value == \"\":\n",
    "        message = \"**Password:** {} (default)\".format(database_password)\n",
    "        printmd(message)\n",
    "    else:\n",
    "        database_password = inputPassword.value\n",
    "        message = \"**Password:** ###########\"\n",
    "        printmd(message)\n",
    "    \n",
    "    printmd(\"------\")\n",
    "    db_connect()\n",
    "        \n",
    "button = widgets.Button(description=\"Connect\")\n",
    "ipd.display(button)\n",
    "button.on_click(on_button_click)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bar_plot(data,title,x,xLabel,y,yLabel,color=None,xAxisRotation=90):\n",
    "\n",
    "    # Bar plot\n",
    "    pylab.rcParams['figure.figsize'] = (12, 8)\n",
    "    seq_col_brew = sns.color_palette(\"Blues_r\", 1)\n",
    "    sns.color_palette(seq_col_brew)\n",
    "    if color != None:\n",
    "        plt = sns.barplot(x=x, y=y, data=data, color=color)\n",
    "    else:\n",
    "        plt = sns.barplot(x=x, y=y, data=data)\n",
    "        \n",
    "    # titles\n",
    "    plt.set_title(title,fontsize=30)\n",
    "    plt.set_xlabel(xLabel,fontsize=12)\n",
    "    plt.set_ylabel(yLabel,fontsize=12)\n",
    "    \n",
    "    # rotate x axis labels\n",
    "    for item in plt.get_xticklabels():\n",
    "        item.set_rotation(xAxisRotation)\n",
    "\n",
    "    # remove scientific notation\n",
    "    plt.ticklabel_format(style='plain', axis='y')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<span style='color:green'>**Connection successful!**</span>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "database_host = 'localhost'\n",
    "database_databasename = 'madlib'\n",
    "database_username = 'gpadmin'\n",
    "database_password = ''\n",
    "database_port = '5432'\n",
    "db_connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function\n",
    "def query_gpdb(query): \n",
    "\n",
    "    cur.execute(query)\n",
    "\n",
    "    colnames = [desc[0] for desc in cur.description]\n",
    "    return pd.DataFrame(cur.fetchall(), columns=colnames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "DROP TABLE IF EXISTS training_data;\n",
    "CREATE TABLE training_data (\n",
    "    a1 TEXT,\n",
    "    a2 TEXT,\n",
    "    a3 TEXT,\n",
    "    a4 FLOAT,\n",
    "    a5 FLOAT,\n",
    "    a6 INTEGER,\n",
    "    a7 INTEGER,\n",
    "    a8 INTEGER,\n",
    "    a9 INTEGER,\n",
    "    a10 INTEGER,\n",
    "    a11 INTEGER,\n",
    "    a12 FLOAT,\n",
    "    a13 FLOAT,\n",
    "    a14 FLOAT,\n",
    "    a15 INTEGER,\n",
    "    a16 FLOAT,\n",
    "    a17 FLOAT,\n",
    "    a18 FLOAT,\n",
    "    a19 FLOAT,\n",
    "    a20 FLOAT,\n",
    "    a21 FLOAT,\n",
    "    a22 FLOAT,\n",
    "    a23 FLOAT,\n",
    "    a24 INTEGER,\n",
    "    a25 FLOAT,\n",
    "    a26 FLOAT,\n",
    "    a27 FLOAT,\n",
    "    a28 FLOAT,\n",
    "    a29 FLOAT,\n",
    "    a30 FLOAT,\n",
    "    a31 FLOAT,\n",
    "    a32 FLOAT,\n",
    "    a33 FLOAT,\n",
    "    a34 FLOAT,\n",
    "    a35 FLOAT,\n",
    "    a36 FLOAT,\n",
    "    a37 FLOAT,\n",
    "    a38 FLOAT,\n",
    "    a39 FLOAT,\n",
    "    a40 FLOAT,\n",
    "    a41 FLOAT,\n",
    "    a42 INTEGER,\n",
    "    y TEXT\n",
    ");\n",
    "\n",
    "COPY training_data FROM '/home/gpadmin/network_data/training.csv' CSV DELIMITER ',';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%sql SET search_path=public,madlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "DROP TABLE IF EXISTS training_data_id;\n",
    "CREATE TABLE training_data_id AS\n",
    "SELECT ROW_NUMBER() OVER()-1 AS id, * FROM training_data;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "DROP TABLE training_data;\n",
    "ALTER TABLE training_data_id RENAME TO training_data;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "SELECT * FROM training_data ORDER BY id LIMIT 5;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "SELECT COUNT(*) FROM training_data;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Eval data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "DROP TABLE IF EXISTS eval_data;\n",
    "CREATE TABLE eval_data (\n",
    "    id INTEGER,\n",
    "    a1 TEXT,\n",
    "    a2 TEXT,\n",
    "    a3 TEXT,\n",
    "    a4 FLOAT,\n",
    "    a5 FLOAT,\n",
    "    a6 INTEGER,\n",
    "    a7 INTEGER,\n",
    "    a8 INTEGER,\n",
    "    a9 INTEGER,\n",
    "    a10 INTEGER,\n",
    "    a11 INTEGER,\n",
    "    a12 FLOAT,\n",
    "    a13 FLOAT,\n",
    "    a14 FLOAT,\n",
    "    a15 INTEGER,\n",
    "    a16 FLOAT,\n",
    "    a17 FLOAT,\n",
    "    a18 FLOAT,\n",
    "    a19 FLOAT,\n",
    "    a20 FLOAT,\n",
    "    a21 FLOAT,\n",
    "    a22 FLOAT,\n",
    "    a23 FLOAT,\n",
    "    a24 INTEGER,\n",
    "    a25 FLOAT,\n",
    "    a26 FLOAT,\n",
    "    a27 FLOAT,\n",
    "    a28 FLOAT,\n",
    "    a29 FLOAT,\n",
    "    a30 FLOAT,\n",
    "    a31 FLOAT,\n",
    "    a32 FLOAT,\n",
    "    a33 FLOAT,\n",
    "    a34 FLOAT,\n",
    "    a35 FLOAT,\n",
    "    a36 FLOAT,\n",
    "    a37 FLOAT,\n",
    "    a38 FLOAT,\n",
    "    a39 FLOAT,\n",
    "    a40 FLOAT,\n",
    "    a41 FLOAT,\n",
    "    a42 INTEGER\n",
    ");\n",
    "\n",
    "COPY eval_data FROM '/home/gpadmin/network_data/eval-rev2-1.csv' DELIMITER ',' CSV HEADER;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "SELECT * FROM eval_data ORDER BY id LIMIT 10;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "SELECT COUNT(*) FROM eval_data;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from imblearn.over_sampling import SMOTENC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training_data = %sql SELECT * FROM training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training_data = pd.read_csv(\"/Users/fmcquillan/Documents/Technical/vmw_ml_fun_jan2021/training.csv\", header=None) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = pd.read_csv(\"/Users/dominovaldano/Dropbox/vbetter/training.csv\", header=None) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data[42][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = list(training_data[42])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X_train = training_data.drop(labels=42, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_counts = %sql SELECT y,COUNT(*) AS c FROM training_data GROUP BY y HAVING COUNT(*) < 1000 ORDER BY c DESC;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Re-arrange training data columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = pd.read_csv('/Users/dominovaldano/Dropbox/vbetter/training.csv', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_floats(tbl):\n",
    "    query = \"SELECT COUNT(*) FROM {tbl} WHERE {col} != ROUND({col})\"\n",
    "    num_floats = []\n",
    "    for c in range(4,43):\n",
    "        col='a'+str(c)\n",
    "        cur.execute(query.format(col=col, tbl=tbl))\n",
    "        res = cur.fetchall()\n",
    "        num_float = res[0][0]\n",
    "        num_floats.append(num_float)\n",
    "    return num_floats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_floats = find_floats('eval_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "float_cols = [ i+3 for i in range(len(eval_floats)) if eval_floats[i] > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = [ x for x in range(3,41) if x not in float_cols ] # Drop column 41 because values are all 0, and drop 42 (y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(cat_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data[float_cols][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_float_cols = len(float_cols)\n",
    "num_int_cols = len(cat_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data[cat_cols][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_int = training_data[cat_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_int[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_float = training_data[float_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_text = training_data[[0,1,2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_xform = pd.concat([training_data_text, training_data_int, training_data_float, training_data[42]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_xform.columns = [ 'c' + str(i) for i in range(41)] + ['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_xform.to_csv('training_data_xform.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_int.columns = training_data_xform.columns[range(3,26)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(training_data_int.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_int[:50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1-Hot Encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_xform = pd.read_csv('/Users/dominovaldano/Dropbox/vbetter/training_data_xform.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql SELECT 100.0*a.c/b.c as fraction,y from (select y, count(*) as c from training_data_xform where c21 > 0 group by y) a join (select y, count(*) as c from training_data_xform group by y) b using (y) order by fraction desc;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "DROP TABLE IF EXISTS training_data_xform_1hot, training_data_xform_1hot_dictionary;\n",
    "SELECT madlib.encode_categorical_variables (\n",
    "        'training_data_xform',                    -- Source table\n",
    "        'training_data_xform_1hot',               -- Output table\n",
    "        'c0,c1,c2,c7,c12,c18'                     -- Categorical columns\n",
    "        );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_xform_1hot = %sql SELECT * FROM training_data_xform_1hot;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_col_order = list(training_data_xform_1hot.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "already_1hot = \"c5 c6 c8 c9 c10 y\".split(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_col_order = [ c for c in old_col_order[1:] if c not in already_1hot ] + already_1hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_1hot = training_data_xform_1hot[new_col_order]  # Re-arrange column order again (but keep labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_1hot[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_1hot.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_1hot.to_csv('full_dataset_1hot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "fulldata_1hot = pd.read_csv('full_dataset_1hot.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = list(fulldata_1hot.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_cols = cols[1:31]  # skip ID, index 30 should be c40 (last numerical feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_cols = fulldata_1hot.columns[31:-1]  # exclude last column 'y'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_numcols = fulldata_1hot[numerical_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_floats32 = np.array(df_numcols.values, dtype=float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ints = fulldata_1hot[binary_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_ints = np.array(df_ints.values, int16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = fulldata_1hot['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = y_train.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = np.array(list(v),dtype=str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('fulldata_y.np','w') as f:\n",
    "    np.save(f,v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('fulldata_int16.np','w') as f:\n",
    "    np.save(f,X_train_ints, allow_pickle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('fulldata_float32','w') as f:\n",
    "    np.save(f,X_train_float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('fulldata_cols.np','w') as f:\n",
    "    np.save(f,cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scale numerical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('fulldata_y.np','r') as f:\n",
    "    y_train = np.load(f, allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('fulldata_int16.np','r') as f:\n",
    "    X_train_int16 = np.load(f, allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('fulldata_float32.np','r') as f:\n",
    "    X_train_float32 = np.load(f, allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.000e+00, 0.000e+00, 0.000e+00, ..., 5.000e-02, 1.000e+00,\n",
       "        1.000e+00],\n",
       "       [5.200e+02, 0.000e+00, 0.000e+00, ..., 0.000e+00, 0.000e+00,\n",
       "        0.000e+00],\n",
       "       [3.320e+02, 7.710e+02, 0.000e+00, ..., 0.000e+00, 0.000e+00,\n",
       "        0.000e+00],\n",
       "       ...,\n",
       "       [1.032e+03, 0.000e+00, 0.000e+00, ..., 0.000e+00, 0.000e+00,\n",
       "        0.000e+00],\n",
       "       [5.200e+02, 0.000e+00, 0.000e+00, ..., 0.000e+00, 0.000e+00,\n",
       "        0.000e+00],\n",
       "       [0.000e+00, 0.000e+00, 0.000e+00, ..., 6.000e-02, 1.000e+00,\n",
       "        1.000e+00]], dtype=float32)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_float32[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO:  make X_train_int16 a sparse array, before saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('fulldata_cols.np','r') as f:\n",
    "    cols = np.load(f, allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_cols = cols[1:31]  # skip ID, index 30 should be c40 (last numerical feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_cols = cols[31:-1]  # exclude last column 'y'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = fulldata_1hot.drop('ID', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "del X_train['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = fulldata_1hot['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-54-b8000c10e254>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# fit_transform the numerical features in the training dataset to a new dataframe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mscaled_numerical_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnumerical_cols\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnumerical_cols\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m#Integrate scaled values to the training set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnumerical_cols\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaled_numerical_cols\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/greenplum-db/ext/python/lib/python2.7/site-packages/sklearn/base.pyc\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    462\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    463\u001b[0m             \u001b[0;31m# fit method of arity 1 (unsupervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 464\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    465\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    466\u001b[0m             \u001b[0;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/greenplum-db/ext/python/lib/python2.7/site-packages/sklearn/preprocessing/data.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    643\u001b[0m         \u001b[0;31m# Reset internal state before fitting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    644\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 645\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartial_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    646\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    647\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpartial_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/greenplum-db/ext/python/lib/python2.7/site-packages/sklearn/preprocessing/data.pyc\u001b[0m in \u001b[0;36mpartial_fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    667\u001b[0m         X = check_array(X, accept_sparse=('csr', 'csc'), copy=self.copy,\n\u001b[1;32m    668\u001b[0m                         \u001b[0mwarn_on_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFLOAT_DTYPES\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 669\u001b[0;31m                         force_all_finite='allow-nan')\n\u001b[0m\u001b[1;32m    670\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    671\u001b[0m         \u001b[0;31m# Even in the case of `with_mean=False`, we update the mean anyway\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/greenplum-db/ext/python/lib/python2.7/site-packages/sklearn/utils/validation.pyc\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    525\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    526\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimplefilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 527\u001b[0;31m                 \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    528\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    529\u001b[0m                 raise ValueError(\"Complex data not supported\\n\"\n",
      "\u001b[0;32m/home/gpadmin/.local/lib/python2.7/site-packages/numpy/core/numeric.pyc\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m    536\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    537\u001b[0m     \"\"\"\n\u001b[0;32m--> 538\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    539\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/gpadmin/.local/lib/python2.7/site-packages/pandas/core/generic.pyc\u001b[0m in \u001b[0;36m__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m   1903\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1904\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__array__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1905\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues_from_object\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1906\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1907\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__array_wrap__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.values_from_object\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/home/gpadmin/.local/lib/python2.7/site-packages/pandas/core/generic.pyc\u001b[0m in \u001b[0;36mget_values\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   5378\u001b[0m                [nan,  3.]])\n\u001b[1;32m   5379\u001b[0m         \"\"\"\n\u001b[0;32m-> 5380\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5381\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5382\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_dtype_counts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/gpadmin/.local/lib/python2.7/site-packages/pandas/core/generic.pyc\u001b[0m in \u001b[0;36mvalues\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   5323\u001b[0m         \"\"\"\n\u001b[1;32m   5324\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_consolidate_inplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5325\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_AXIS_REVERSED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5327\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/gpadmin/.local/lib/python2.7/site-packages/pandas/core/internals/managers.pyc\u001b[0m in \u001b[0;36mas_array\u001b[0;34m(self, transpose, items)\u001b[0m\n\u001b[1;32m    766\u001b[0m             \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 768\u001b[0;31m             \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_interleave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    769\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    770\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtranspose\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/gpadmin/.local/lib/python2.7/site-packages/pandas/core/internals/managers.pyc\u001b[0m in \u001b[0;36m_interleave\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    785\u001b[0m             \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'object'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    786\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 787\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    788\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m         \u001b[0mitemmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# fit_transform the numerical features in the training dataset to a new dataframe\n",
    "scaled_numerical_cols = pd.DataFrame(scaler.fit_transform(X_train[numerical_cols]),columns=numerical_cols, index=X_train.index)\n",
    "#Integrate scaled values to the training set\n",
    "for col in numerical_cols:\n",
    "    X_train[col] = scaled_numerical_cols[col]\n",
    "    \n",
    "#Transform the numerical features inthe training dataset to a new dataframe\n",
    "# scaled_numfeats_test = pd.DataFrame(scaler.transform(X_test[num_cols_names]),\n",
    "#                                    columns=num_cols_names, index= X_test.index)\n",
    "#Integrate scaled values to the test set\n",
    "# for col in num_cols_names:\n",
    "   #  X_test[col] = scaled_numfeats_test[col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.to_csv('x.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tra = X_train[458863:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del X_tra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tra = X_train[4588163:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tra.to_csv('X_tra.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.to_csv('y.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(23):\n",
    "    col = 'c' + str(i+3)\n",
    "    distinct = list(set(training_data_int[col]))\n",
    "    print('{} : {}'.format(col, len(distinct)))\n",
    "    if len(distinct) < 30:\n",
    "        print(distinct)\n",
    "    # counts = training_data_int.groupby(col)[col].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = Counter(training_data_int['c21'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(pd.Categorical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_xform.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "training_data_xform[training_data_xform.y == 'normal'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_values = np.array(list(set(training_data_xform['y'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_hist(col, df=training_data_xform):\n",
    "    for y in y_values:\n",
    "        df_y = df[df.y == y]\n",
    "        df_y.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_hist('c20')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_xform.groupby(['y', 'c21'])['y', 'c21'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql SELECT data_type, target_column, distinct_values, positive_values, zero_values, mean, variance FROM training_summary ORDER BY distinct_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from imblearn.over_sampling import SMOTENC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a23, a35:  0-255 but mostly 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql SELECT a23,y, COUNT(*) FROM training_data GROUP BY 1,2 ORDER BY y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_counts = class_counts[:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sampling_strategy(classes):\n",
    "    n = [10] * (len(classes)-1) # Just take 10 samples of each\n",
    "    strat = { classes[i] : n[i] for i in range(len(classes)-1) }\n",
    "    return strat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strat = sampling_strategy(class_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = training_1hot_class19.drop('y', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del X_train['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.columns.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = training_1hot_class19['y'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(training_1hot_class19.columns).index('y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_1hot_class19.columns[36]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "re.match(r'.*_.*', 'hi_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_col_index = [ re.match(r'.*_.*',c) is not None for c in list(X_train.columns)  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_col_index = np.array(cat_col_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_col_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.columns[range(2,7)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_col_index[range(2,7)] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_col_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_col_index[[34,35]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.columns[[34,35]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm = SMOTENC(categorical_features=cat_col_index, k_neighbors=1, random_state=123, n_jobs=4,sampling_strategy={'class19' : 20 })\n",
    "X_trainres, y_trainres = sm.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_trainres.shape, y_trainres.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_trainres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_trainres.shape = (31,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(X_trainres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[128] = y_trainres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = list(X_train.columns) + ['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.y == 'class19']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yres = list(y_trainres[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = Counter(yres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in counts.keys():\n",
    "    print(\"{} : {}\".format(k,counts[k]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_res = pd.read_csv('df_res.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data.groupby(42)[42].count().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_res.groupby('y')['y'].count().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_res[df_res.y == 'class02']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data[training_data[42] == 'class02']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data.groupby(0)[0].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(training_data.groupby(1)[1].count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(training_data.groupby(2)[2].count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Smote Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "rng = np.random.RandomState(42)\n",
    "n_samples = 50\n",
    "X = np.empty((n_samples, 3), dtype=object)\n",
    "X[:, 0] = rng.choice(['A', 'B', 'C'], size=n_samples).astype(object)\n",
    "X[:, 1] = rng.randn(n_samples)\n",
    "X[:, 2] = rng.randint(3, size=n_samples)\n",
    "y = np.array([0] * 20 + [1] * 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTENC\n",
    "smote_nc = SMOTENC(categorical_features=[0, 2], random_state=0)\n",
    "X_resampled, y_resampled = smote_nc.fit_resample(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_resampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_resampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'a' : [ 1, 2, 3, 4, 5], 'b' : [2, 4, 6, 8, 10], 'c' : [0, 1, 1, 0, 1], 'd' : [1, 1, 0, 0, 1], 't': ['hi', 'bye', 'please', 'welcome', 'welcome'], 'y' : ['YES', 'YES', 'NO','NO', 'NO']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df.drop('y', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = df.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm = SMOTENC(categorical_features=[4], k_neighbors=1, random_state=123, n_jobs=4,sampling_strategy={'NO' : 100 })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_trainres, y_trainres = sm.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_res = pd.DataFrame(X_trainres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_res[0] = df_res[0].apply(lambda x : int(round(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "round(3.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(df_res.apply)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for r in df_res:\n",
    "    print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(df_res.query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_res.insert(4, 'y', y_trainres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_res.sort_values('y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_res.groupby('y')[0].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from numpy.random import RandomState\n",
    "from sklearn.datasets import make_classification\n",
    "from imblearn.over_sampling import SMOTENC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_classification(n_classes=2, class_sep=2,\n",
    "weights=[0.1, 0.9], n_informative=3, n_redundant=1, flip_y=0, n_features=20, n_clusters_per_class=1, n_samples=1000, random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<a id=\"external_table\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Audit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"summary_statistics\"></a>\n",
    "Summary Statistics\n",
    "\n",
    "https://madlib.apache.org/docs/latest/group__grp__summary.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "DROP TABLE IF EXISTS training_summary;\n",
    "SELECT * FROM madlib.summary( 'training_data',   -- Source table\n",
    "                              'training_summary'    -- Output table\n",
    "                            );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "SELECT * FROM training_summary;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "DROP TABLE IF EXISTS eval_summary;\n",
    "SELECT * FROM madlib.summary( 'eval_data',   -- Source table\n",
    "                              'eval_summary'    -- Output table\n",
    "                            );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "SELECT * FROM eval_summary;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<a id=\"de_categorical\"></a>\n",
    "#### Categorical Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "catColumns = ['a1','a2','a3', 'a6','a7','a8', 'a9',\n",
    "              'a10','a11', 'a15','a24','a42',\n",
    "              'y']\n",
    "\n",
    "def bar_plot(data,title,x,xLabel,y,yLabel,color=None,xAxisRotation=90):\n",
    "\n",
    "    # Bar plot\n",
    "    pylab.rcParams['figure.figsize'] = (12, 8)\n",
    "    seq_col_brew = sns.color_palette(\"Blues_r\", 1)\n",
    "    sns.color_palette(seq_col_brew)\n",
    "    if color != None:\n",
    "        plt = sns.barplot(x=x, y=y, data=data, color=color)\n",
    "    else:\n",
    "        plt = sns.barplot(x=x, y=y, data=data)\n",
    "        \n",
    "    # titles\n",
    "    plt.set_title(title,fontsize=30)\n",
    "    plt.set_xlabel(xLabel,fontsize=12)\n",
    "    plt.set_ylabel(yLabel,fontsize=12)\n",
    "    \n",
    "    # rotate x axis labels\n",
    "    for item in plt.get_xticklabels():\n",
    "        item.set_rotation(xAxisRotation)\n",
    "\n",
    "    # remove scientific notation\n",
    "    plt.ticklabel_format(style='plain', axis='y')\n",
    "\n",
    "\n",
    "def get_cat_data_frame(col):\n",
    "    query = \"\"\"\n",
    "        SELECT *\n",
    "              ,round((record_count * 100.0) / sum(record_count) OVER(),2) AS perc_records\n",
    "        FROM (\n",
    "            SELECT {} AS col\n",
    "                  ,count(*) AS record_count\n",
    "            FROM public.training_data\n",
    "            GROUP BY 1\n",
    "        ) foo\n",
    "        ORDER BY perc_records DESC\n",
    "    \"\"\".format(col)\n",
    "    cur.execute(query)\n",
    "\n",
    "    colnames = [desc[0] for desc in cur.description]\n",
    "    return pd.DataFrame(cur.fetchall(), columns=colnames)\n",
    "    \n",
    "def on_cat_selection(res):\n",
    "    if res['type'] == 'change' and res['name'] == 'value':\n",
    "        ipd.clear_output()\n",
    "        printmd(\"-----\\n **Select Column:**\")\n",
    "        ipd.display(catDropdown)\n",
    "        df = get_cat_data_frame(res['new'])\n",
    "        bar_plot(df,res['new'],\"col\",res['new'],\"perc_records\",\"% Records\", None, 0)\n",
    "    \n",
    "catDropdown = widgets.Dropdown(\n",
    "    options=catColumns,\n",
    "    value=catColumns[0],\n",
    "    description='Column:',\n",
    "    disabled=False,\n",
    ")\n",
    "\n",
    "catDropdown.observe(on_cat_selection)\n",
    "printmd(\"-----\\n **Select Column:**\")\n",
    "ipd.display(catDropdown)\n",
    "df = get_cat_data_frame(catColumns[0])\n",
    "bar_plot(df,catColumns[0],\"col\",catColumns[0],\"perc_records\",\"% Records\", None, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "* Low % of values in any one class can skew model results and/or create unstable model. In practice we may consider merging and/or excluding some groups. (e.g. a4: [i], a5: [gg], a7: [z,j,dd,n,o), a13: [s,p])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<a id=\"de_continuous\"></a>\n",
    "#### Continuous Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "contColumns = ['a4', 'a5','a12', 'a13', 'a14', 'a16', \n",
    "               'a17', 'a18', 'a19', 'a20', 'a21', \n",
    "               'a22', 'a23', 'a25', 'a26', 'a27', \n",
    "               'a28', 'a29', 'a30', 'a31', 'a32', \n",
    "               'a33', 'a34', 'a35', 'a36', 'a37', \n",
    "               'a38', 'a39', 'a40', 'a41']\n",
    "sliderValue = 20\n",
    "colName = contColumns[0]\n",
    "\n",
    "def get_cont_data_frame(col, buckets):\n",
    "    query = \"\"\"\n",
    "        WITH aggs AS (\n",
    "            SELECT min({c}) AS min,\n",
    "                   max({c}) AS max\n",
    "              FROM training_data\n",
    "        )\n",
    "        SELECT width_bucket({c}, min, max, {b}-1) AS bucket,\n",
    "               ('[' || min({c}) || ',' || max({c}) || ')')::text as range,\n",
    "               count(*) as freq\n",
    "        FROM training_data, aggs\n",
    "        GROUP BY bucket\n",
    "        ORDER BY bucket\n",
    "    \"\"\".format(c=col, b=buckets)\n",
    "    cur.execute(query)\n",
    "\n",
    "    colnames = [desc[0] for desc in cur.description]\n",
    "    return pd.DataFrame(cur.fetchall(), columns=colnames)\n",
    "    \n",
    "def graph_reset():\n",
    "    ipd.clear_output()\n",
    "    printmd(\"-----\\n\")\n",
    "    ipd.display(widgets.HBox((contDropdown,bucketsSlider)))\n",
    "    printmd(\"-----\\n\")\n",
    "    df = get_cont_data_frame(colName,sliderValue)\n",
    "    bar_plot(df,colName,\"range\",colName,\"freq\",\"Frequency\", \"#4378E2\")    \n",
    "    \n",
    "def on_cont_selection(res):\n",
    "    global colName\n",
    "    if res['type'] == 'change' and res['name'] == 'value':\n",
    "        colName = res['new']\n",
    "        graph_reset()\n",
    "        \n",
    "def on_slider_selection(res):\n",
    "    global sliderValue\n",
    "    if res['new'] == {} and res['old']:\n",
    "        sliderValue = res['old']['value']\n",
    "        graph_reset()\n",
    "    \n",
    "# Look at log transforms\n",
    "#colsAddLogs = contColumns + [\"log({} + 1)\".format(c) for c in contColumns]\n",
    "colsAddLogs = contColumns\n",
    "\n",
    "contDropdown = widgets.Dropdown(\n",
    "    options=colsAddLogs,\n",
    "    value=colsAddLogs[0],\n",
    "    description='Column:',\n",
    "    disabled=False,\n",
    ")\n",
    "\n",
    "bucketsSlider = widgets.IntSlider(\n",
    "    value=sliderValue,\n",
    "    min=5,\n",
    "    max=50,\n",
    "    step=1,\n",
    "    description='# Buckets:',\n",
    "    disabled=False,\n",
    "    continuous_update=False,\n",
    "    orientation='horizontal',\n",
    "    readout=True,\n",
    "    readout_format='d'\n",
    ")\n",
    "\n",
    "contDropdown.observe(on_cont_selection)\n",
    "bucketsSlider.observe(on_slider_selection)\n",
    "\n",
    "graph_reset()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "* a15 large number of outliers - consider correcting\n",
    "* Consider variable transformation if test non-tree based algorithm\n",
    "* Histogram values are being calculated in the database - minimal data movement back to client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "DROP TABLE IF EXISTS training_data_encoded, training_data_encoded_dictionary;\n",
    "SELECT madlib.encode_categorical_variables (\n",
    "        'training_data',            -- Source table\n",
    "        'training_data_encoded',      -- Output table\n",
    "        'a1, a2, a3'                        -- Categorical columns\n",
    "        );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "select * from training_data_encoded limit 5;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Sample training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "drop table if exists training_data_work1;\n",
    "create table training_data_work1 as\n",
    "(select * from training_data_encoded where y='class19' \n",
    "                                            or y='class12'\n",
    "                                            or y='class13');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "drop table if exists training_data_work2, training_data_work2_summary;\n",
    "select madlib.cols2vec('training_data_work1',\n",
    "                       'training_data_work2',\n",
    "                       '*',\n",
    "                       'y',\n",
    "                       'y'\n",
    "                       );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "ALTER TABLE training_data_work2 ADD column pid serial;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "DROP TABLE IF EXISTS training_data_work3;\n",
    "\n",
    "CREATE TABLE training_data_work3 AS\n",
    "(SELECT * FROM madlib.kmeanspp(\n",
    "    'training_data_work2',                  -- points table\n",
    "    'feature_vector',                      -- column name in point table\n",
    "    3,\n",
    "    'madlib.dist_norm1',   -- distance function\n",
    "    'madlib.avg',                  -- aggregate function\n",
    "    20,                            -- max iterations\n",
    "    0.001                         -- minimum fraction of centroids reassigned to continue iterating\n",
    "));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "select * from training_data_work3;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "DROP TABLE IF EXISTS point_cluster_map;\n",
    "CREATE TABLE point_cluster_map AS\n",
    "SELECT data.*, (madlib.closest_column(centroids, feature_vector, 'madlib.squared_dist_norm2')).*\n",
    "FROM training_data_work2 as data, training_data_work3;\n",
    "ALTER TABLE point_cluster_map RENAME column_id to cluster_id; -- change column name\n",
    "SELECT y, pid, cluster_id, distance FROM point_cluster_map ORDER BY cluster_id, distance desc;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "SELECT * FROM madlib.simple_silhouette( 'training_data_work2',          -- Input points table\n",
    "                                              'feature_vector',              -- Points column in input table\n",
    "                                              (select centroids from training_data_work3),           -- Column in centroids table containing centroids\n",
    "                                              'madlib.squared_dist_norm2'   -- Distance function\n",
    "                                      );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "DROP TABLE IF EXISTS km_points_silh;\n",
    "SELECT * FROM madlib.simple_silhouette_points( 'training_data_work2',          -- Input points table\n",
    "                                              'km_points_silh',      -- Output table\n",
    "                                              'pid',                 -- Point ID column in input table\n",
    "                                              'feature_vector',              -- Points column in input table\n",
    "                                              'training_data_work3',           -- Centroids table\n",
    "                                              'centroids',           -- Column in centroids table containing centroids\n",
    "                                              'madlib.squared_dist_norm2'   -- Distance function\n",
    "                                      );\n",
    "SELECT * FROM km_points_silh ORDER BY centroid_id;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "whole table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "drop table if exists training_data_work10, training_data_work10_summary;\n",
    "select madlib.cols2vec('training_data_encoded',\n",
    "                       'training_data_work10',\n",
    "                       '*',\n",
    "                       'y',\n",
    "                       'y'\n",
    "                       );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "DROP TABLE IF EXISTS point_cluster_map;\n",
    "CREATE TABLE point_cluster_map AS\n",
    "SELECT data.*, (madlib.closest_column(centroids, feature_vector, 'madlib.squared_dist_norm2')).*\n",
    "FROM training_data_work10 as data, training_data_work3;\n",
    "ALTER TABLE point_cluster_map RENAME column_id to cluster_id; -- change column name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "select * from point_cluster_map limit 5;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%sql \n",
    "select count(*) from point_cluster_map where cluster_id = 0 and distance < 130415.0;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "DROP TABLE IF EXISTS k_auto, k_auto_summary;\n",
    "\n",
    "SELECT madlib.kmeanspp_auto(\n",
    "    'training_data_work2',                  -- points table\n",
    "    'k_auto',                      -- output table\n",
    "    'feature_vector',                      -- column name in point table\n",
    "    ARRAY[2,3,4],              -- k values to try\n",
    "    'madlib.squared_dist_norm2',   -- distance function\n",
    "    'madlib.avg',                  -- aggregate function\n",
    "    20,                            -- max iterations\n",
    "    0.001,                         -- minimum fraction of centroids reassigned to continue iterating\n",
    "    1.0,                           -- centroid seed\n",
    "    'silhouette'                         -- k selection algorithm (silhouette or elbow or both)\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "SELECT * FROM k_auto_summary;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "SELECT * FROM k_auto ORDER BY k;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# get range of k values tested\n",
    "k_range = %sql SELECT k FROM k_auto ORDER BY k;\n",
    "\n",
    "# outer loop on k\n",
    "# plot clusters for each k value\n",
    "for n_clusters in k_range:\n",
    "    \n",
    "    # create table mapping each point to its centroid\n",
    "    kval = n_clusters[0]\n",
    "    %sql DROP TABLE IF EXISTS k_plot1;\n",
    "    %sql CREATE TABLE k_plot1 AS (SELECT data.*, (madlib.closest_column(centroids, feature_vector, 'madlib.squared_dist_norm2')).column_id as cluster_id FROM training_data_work2 as data, k_auto WHERE k=$kval);\n",
    "\n",
    "    # get info from tables and reshape to np arrays    \n",
    "    # number of points\n",
    "    num_points_proxy= %sql SELECT COUNT(*) FROM k_plot1;\n",
    "    num_points= num_points_proxy[0][0]\n",
    "    \n",
    "    # points\n",
    "    points_proxy = %sql SELECT feature_vector FROM k_plot1 ORDER BY pid;\n",
    "    points = np.array(points_proxy).reshape(num_points,123) \n",
    "    \n",
    "    # cluster id\n",
    "    cluster_id_proxy = %sql SELECT cluster_id FROM k_plot1 ORDER BY pid;\n",
    "    cluster_id = np.array(cluster_id_proxy).reshape(num_points)\n",
    "    \n",
    "    # centroids\n",
    "    centroids_proxy = %sql SELECT centroids FROM k_auto WHERE k=$kval;\n",
    "    centers = np.array(centroids_proxy[0][0]).reshape(kval,123)\n",
    "    \n",
    "    # The silhouette_score gives the average value for all the samples.\n",
    "    # This gives a perspective into the density and separation of the formed\n",
    "    # clusters\n",
    "    silhouette_avg = %sql SELECT silhouette FROM k_auto WHERE k=$kval;\n",
    "    print(\"For n_clusters =\", kval,\n",
    "          \"The average silhouette_score is :\", silhouette_avg)\n",
    "    \n",
    "    # Create a subplot with 1 row and 2 columns\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "    fig.set_size_inches(18, 7)\n",
    "      \n",
    "    # The 1st subplot is the silhouette plot\n",
    "    # The silhouette coefficient can range from -1, 1 but in this example all\n",
    "    # lie within [-0.1, 1]\n",
    "    ax1.set_xlim([-0.1, 1])\n",
    "    # The (n_clusters+1)*10 is for inserting blank space between silhouette\n",
    "    # plots of individual clusters, to demarcate them clearly.\n",
    "    len_X = %sql select count(*) from training_data_work2;\n",
    "    len_X = len_X[0][0]\n",
    "    ax1.set_ylim([0, len_X + (kval + 1) * 10])\n",
    "    \n",
    "    y_lower = 10\n",
    "    \n",
    "    # inner loop on number of centroids \n",
    "    for i in range(kval):\n",
    "\n",
    "        %sql DROP TABLE IF EXISTS points_distr1;\n",
    "        %sql SELECT * FROM madlib.simple_silhouette_points( 'training_data_work2', 'points_distr1', 'pid', 'feature_vector', (SELECT centroids FROM k_auto WHERE k=$kval), 'madlib.squared_dist_norm2');\n",
    "        ith_cluster_silhouette_values_proxy = %sql SELECT silh from points_distr1 WHERE centroid_id=$i ORDER BY silh;\n",
    "        ith_cluster_silhouette_values = np.array(ith_cluster_silhouette_values_proxy).reshape(len(ith_cluster_silhouette_values_proxy))\n",
    "        \n",
    "        size_cluster_i_proxy = %sql SELECT COUNT(*) from points_distr1 WHERE centroid_id=$i;\n",
    "        size_cluster_i = size_cluster_i_proxy[0][0]\n",
    "\n",
    "        y_upper = y_lower + size_cluster_i\n",
    "\n",
    "        color = cm.nipy_spectral(float(i) / kval)\n",
    "        ax1.fill_betweenx(np.arange(y_lower, y_upper), \n",
    "                  0, ith_cluster_silhouette_values, \n",
    "                  facecolor=color, edgecolor=color, alpha=0.7);\n",
    "        \n",
    "        # Label the silhouette plots with their cluster numbers at the middle\n",
    "        ax1.text(-0.05, y_lower + 0.5 * size_cluster_i, str(i));\n",
    "\n",
    "        # Compute the new y_lower for next plot\n",
    "        y_lower = y_upper + 10  # 10 for the 0 samples\n",
    "           \n",
    "    ax1.set_title(\"Silhouette plot for the various clusters.\")\n",
    "    ax1.set_xlabel(\"Silhouette coefficient values\")\n",
    "    ax1.set_ylabel(\"Cluster label\")\n",
    "\n",
    "    # The vertical line for average silhouette score of all the values\n",
    "    ax1.axvline(x=silhouette_avg, color=\"red\", linestyle=\"--\")\n",
    "\n",
    "    ax1.set_yticks([])  # Clear the yaxis labels / ticks\n",
    "    ax1.set_xticks([-0.1, 0, 0.2, 0.4, 0.6, 0.8, 1])\n",
    "    \n",
    "    # 2nd Plot showing the actual clusters formed\n",
    "    centroids = %sql SELECT centroid_id FROM points_distr1 ORDER BY pid;\n",
    "    cluster_labels = np.array(centroids).reshape(len(centroids))\n",
    "    \n",
    "    colors = cm.nipy_spectral(cluster_labels.astype(float) / kval)\n",
    "    #ax2.scatter(X[:, 0], X[:, 1], marker='.', s=30, lw=0, alpha=0.7,\n",
    "    #            c=colors, edgecolor='k')\n",
    "\n",
    "    # Labeling the clusters\n",
    "    # Draw white circles at cluster centers\n",
    "    #ax2.scatter(centers[:, 0], centers[:, 1], marker='o',\n",
    "    #            c=\"white\", alpha=1, s=200, edgecolor='k')\n",
    "\n",
    "    #for i, c in enumerate(centers):\n",
    "    #    ax2.scatter(c[0], c[1], marker='$%d$' % i, alpha=1,\n",
    "    #                s=50, edgecolor='k')\n",
    "\n",
    "    #ax2.set_title(\"Visualization of the clustered data.\")\n",
    "    #ax2.set_xlabel(\"Feature space for the 1st feature\")\n",
    "    #ax2.set_ylabel(\"Feature space for the 2nd feature\")\n",
    "\n",
    "    plt.suptitle((\"Silhouette analysis for KMeans clustering on sample data \"\n",
    "                  \"with n_clusters = %d\" % kval),\n",
    "                 fontsize=14, fontweight='bold')\n",
    "\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "len_X = %sql select count(*) from training_data_work2;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "len_X[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_res = %sql SELECT * FROM 'df_res.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Nearest neighbors - v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "drop table if exists temp1;\n",
    "create table temp1 as\n",
    "select * from training_data_encoded where y='class19' or y='class12';\n",
    "select * from temp1;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "DROP TABLE IF EXISTS temp1_summary;\n",
    "SELECT * FROM madlib.summary( 'temp1',   -- Source table\n",
    "                              'temp1_summary',    -- Output table\n",
    "                              NULL,      -- summarize all columns\n",
    "                              'y'    -- grouping \n",
    "                            );\n",
    "select group_by_value, lower(target_column)::VARCHAR, column_number, mean from temp1_summary  where group_by='y' order by group_by, group_by_value, column_number;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "DROP TABLE IF EXISTS temp2;\n",
    "create table temp2 as\n",
    "select group_by_value, target_column, mean from temp1_summary \n",
    "  where (target_column='a4' or target_column='a5') and group_by_value<>'None'\n",
    "  order by group_by_value, target_column;\n",
    "select * from temp2 order by group_by_value, target_column;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "DROP TABLE IF EXISTS temp3;\n",
    "SELECT madlib.pivot('temp2', 'temp3', 'group_by_value', 'target_column', 'mean');\n",
    "SELECT * FROM temp3;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Nearest neighbors - v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "drop table if exists temp1;\n",
    "  create table temp1 as \n",
    "  select * from training_data;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "drop table if exists temp2;\n",
    "  create table temp2 as  \n",
    "  select LOWER(a1) as a1, LOWER(a2) as a2, LOWER(a3) as a3, \n",
    "    a4,\n",
    "    a5,\n",
    "    a6 ,\n",
    "    a7 ,\n",
    "    a8 ,\n",
    "    a9 ,\n",
    "    a10 ,\n",
    "    a11 ,\n",
    "    a12 ,\n",
    "    a13 ,\n",
    "    a14 ,\n",
    "    a15 ,\n",
    "    a16 ,\n",
    "    a17 ,\n",
    "    a18 ,\n",
    "    a19 ,\n",
    "    a20 ,\n",
    "    a21 ,\n",
    "    a22 ,\n",
    "    a23 ,\n",
    "    a24 ,\n",
    "    a25 ,\n",
    "    a26 ,\n",
    "    a27 ,\n",
    "    a28 ,\n",
    "    a29 ,\n",
    "    a30 ,\n",
    "    a31 ,\n",
    "    a32 ,\n",
    "    a33 ,\n",
    "    a34 ,\n",
    "    a35 ,\n",
    "    a36 ,\n",
    "    a37 ,\n",
    "    a38 ,\n",
    "    a39 ,\n",
    "    a40 ,\n",
    "    a41 ,\n",
    "    a42 ,\n",
    "    y from temp1;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "select * from temp2 limit 5;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "DROP TABLE IF EXISTS training_data_encoded, training_data_encoded_dictionary;\n",
    "SELECT madlib.encode_categorical_variables (\n",
    "        'temp2',            -- Source table\n",
    "        'training_data_encoded',      -- Output table\n",
    "        'a1, a2, a3'                        -- Categorical columns\n",
    "        );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "select * from training_data_encoded limit 5;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "DROP TABLE IF EXISTS training_data_encoded_summary;\n",
    "SELECT * FROM madlib.summary( 'training_data_encoded',   -- Source table\n",
    "                              'training_data_encoded_summary',    -- Output table\n",
    "                              NULL,      -- summarize all columns\n",
    "                              'y',    -- grouping \n",
    "                             NULL,\n",
    "                             NULL,\n",
    "                             NULL,\n",
    "                             NULL,\n",
    "                             NULL,\n",
    "                             5\n",
    "                            );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "select group_by, group_by_value, target_column, column_number, mean, variance, min, max from training_data_encoded_summary where target_column='a5' order by group_by, group_by_value, column_number;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "drop table if exists training_data_encoded_summary_all;\n",
    "create table training_data_encoded_summary_all as\n",
    "  select * from training_data_encoded_summary where group_by is NULL;\n",
    "select * from training_data_encoded_summary_all order by column_number;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "drop table if exists work1;\n",
    "create table work1 as \n",
    "  select * from training_data_encoded limit 10;\n",
    "select * from work1;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "drop table if exists drop table if exists work2;\n",
    "create table work2 as\n",
    "DROP TABLE IF EXISTS training_data_encoded_summary;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "drop table if exists temp3;\n",
    "create table temp3 as\n",
    "select * from training_data_encoded where y='class19';\n",
    "select * from temp3;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "DROP TABLE IF EXISTS temp4;\n",
    "create table temp4 as\n",
    "select * from temp3_summary where group_by = 'y';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "DROP TABLE IF EXISTS temp5;\n",
    "SELECT madlib.pivot('temp4', 'temp5', 'group_by_value', 'target_column', 'mean');\n",
    "SELECT * FROM temp5;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "drop table if exists temp6, temp6_summary;\n",
    "select madlib.cols2vec('temp5',\n",
    "                       'temp6',\n",
    "                       '*',\n",
    "                       'group_by_value',\n",
    "                       'group_by_value'\n",
    "                       );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "alter table temp6\n",
    "rename column group_by_value to y;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "select * from temp6;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "drop table if exists temp7, temp7_summary;\n",
    "select madlib.cols2vec('training_data_encoded',\n",
    "                       'temp7',\n",
    "                       '*',\n",
    "                       'y',\n",
    "                       'y'\n",
    "                       );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "select * from temp7 limit 5;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "create table temp8 as\n",
    "  select temp6.y as from_class , temp7.y as to_class, madlib.squared_dist_norm2(temp6.feature_vector, temp7.feature_vector) from temp6, temp7;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "select * from temp8 order by squared_dist_norm2 asc limit 100;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "----\n",
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<a id=\"fe_continuous\"></a>\n",
    "#### Continuous Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# continuos features (seperated out incase feature transformations are required)\n",
    "query = \"\"\"\n",
    "    DROP TABLE IF EXISTS public.model_inputs_cont;\n",
    "    CREATE TABLE public.model_inputs_cont AS\n",
    "    SELECT _id\n",
    "          ,a16 AS approval\n",
    "          ,a2\n",
    "          ,a3\n",
    "          ,a8\n",
    "          ,a11\n",
    "          ,a14\n",
    "          ,a15\n",
    "    FROM public.credit_application_data\n",
    "    DISTRIBUTED BY (_id);\n",
    "    SELECT * FROM public.model_inputs_cont LIMIT 0;\n",
    "\"\"\"\n",
    "cur.execute(query)\n",
    "\n",
    "contFeatureNames = [desc[0] for desc in cur.description]\n",
    "contFeatureNames.remove('_id')\n",
    "contFeatureNames.remove('approval')\n",
    "\n",
    "query = \"\"\"\n",
    "    SELECT *\n",
    "    FROM public.model_inputs_cont\n",
    "\"\"\"\n",
    "df = query_gpdb(query)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<a id=\"fe_one_hot\"></a>\n",
    "#### One Hot Encode Categorical Features\n",
    "\n",
    "https://madlib.apache.org/docs/latest/group__grp__encode__categorical.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# encode categorical features\n",
    "query = \"\"\"\n",
    "    DROP TABLE IF EXISTS public.model_inputs_cat;\n",
    "    SELECT madlib.encode_categorical_variables (\n",
    "        'public.credit_application_data',\n",
    "        'public.model_inputs_cat',\n",
    "        'a1,a4,a5,a6,a7,a9,a10,a12,a13',\n",
    "        NULL,\n",
    "        '_id',\n",
    "        NULL,\n",
    "        'a1=b, a4=y, a5=p, a6=x, a7=z, a9=false, a10=false, a12=false, a13=s'\n",
    "    );\n",
    "\"\"\"\n",
    "cur.execute(query)\n",
    "\n",
    "query = \"\"\"\n",
    "    SELECT *\n",
    "    FROM public.model_inputs_cat\n",
    "\"\"\"\n",
    "cur.execute(query)\n",
    "\n",
    "colnames = [desc[0] for desc in cur.description]\n",
    "df = pd.DataFrame(cur.fetchall(), columns=colnames)\n",
    "\n",
    "colnames.remove('_id')\n",
    "catFeatureNames = colnames\n",
    "featureNames = contFeatureNames + catFeatureNames\n",
    "print(featureNames)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<a id=\"fe_combine\"></a>\n",
    "#### Combine Continuous & Categorical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# combine feature tables\n",
    "query = \"\"\"\n",
    "    DROP TABLE IF EXISTS public.model_inputs;\n",
    "    CREATE TABLE public.model_inputs AS\n",
    "    SELECT *\n",
    "    FROM public.model_inputs_cat\n",
    "    JOIN public.model_inputs_cont\n",
    "    USING (_id);\n",
    "\"\"\"\n",
    "cur.execute(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<a id=\"fe_cats_dep\"></a>\n",
    "#### Plot Categorical Features By Response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def bar_plot_groupby(data, title,x,xLabel,y,yLabel,groupby,color=None,axisRotation=90):\n",
    "\n",
    "    # Bar plot\n",
    "    pylab.rcParams['figure.figsize'] = (12, 8)\n",
    "    seq_col_brew = sns.color_palette(\"Blues_r\", 1)\n",
    "    sns.color_palette(seq_col_brew)\n",
    "    if color != None:\n",
    "        plt = sns.barplot(x=x, y=y, data=data, color=color, hue=groupby)\n",
    "    else:\n",
    "        plt = sns.barplot(x=x, y=y, data=data, hue=groupby)\n",
    "        \n",
    "    # titles\n",
    "    plt.set_title(title,fontsize=30)\n",
    "    plt.set_xlabel(xLabel,fontsize=16)\n",
    "    plt.set_ylabel(yLabel,fontsize=16)\n",
    "    \n",
    "    # rotate x axis labels\n",
    "    for item in plt.get_xticklabels():\n",
    "        item.set_rotation(axisRotation)\n",
    "\n",
    "    # remove scientific notation\n",
    "    plt.ticklabel_format(style='plain', axis='y')\n",
    "\n",
    "def get_cat_gb_data_frame(col):\n",
    "    query = \"\"\"\n",
    "        SELECT *\n",
    "              ,round((record_count * 100.0) / sum(record_count) OVER(PARTITION BY col),2) AS perc_records\n",
    "        FROM (\n",
    "            SELECT {} AS col\n",
    "                  ,approval\n",
    "                  ,count(*) AS record_count\n",
    "            FROM public.model_inputs\n",
    "            GROUP BY 1,2\n",
    "        ) foo\n",
    "        ORDER BY 1,2\n",
    "    \"\"\".format(col)\n",
    "    cur.execute(query)\n",
    "\n",
    "    colnames = [desc[0] for desc in cur.description]\n",
    "    return pd.DataFrame(cur.fetchall(), columns=colnames)\n",
    "    \n",
    "def on_cat_gb_selection(res):\n",
    "    if res['type'] == 'change' and res['name'] == 'value':\n",
    "        ipd.clear_output()\n",
    "        printmd(\"-----\\n **Select Column:**\")\n",
    "        ipd.display(catGPDropdown)\n",
    "        df = get_cat_gb_data_frame(res['new'])\n",
    "        bar_plot_groupby(df,res['new'],\"col\",res['new'],\"perc_records\",\"% Class Records\", \"approval\")\n",
    "    \n",
    "catGPDropdown = widgets.Dropdown(\n",
    "    options=catFeatureNames,\n",
    "    value=catFeatureNames[0],\n",
    "    description='Column:',\n",
    "    disabled=False,\n",
    ")\n",
    "\n",
    "catGPDropdown.observe(on_cat_gb_selection)\n",
    "printmd(\"-----\\n **Select Column:**\")\n",
    "ipd.display(catGPDropdown)\n",
    "df = get_cat_gb_data_frame(catFeatureNames[0])\n",
    "bar_plot_groupby(df,catFeatureNames[0],\"col\",catFeatureNames[0],\"perc_records\",\"% Class Records\",\"approval\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "* a9_true appears to be a strong variable due to seperate between classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<a id=\"fe_chi_sq\"></a>\n",
    "#### Chi-squared testing\n",
    "\n",
    "https://en.wikipedia.org/wiki/Chi-squared_test\n",
    "\n",
    "https://madlib.apache.org/docs/latest/group__grp__stats__tests.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def chi2_gof_test(feature_name, response):\n",
    "    query = \"\"\"\n",
    "        WITH freq AS (\n",
    "            SELECT {feature_name}\n",
    "                  ,{response}\n",
    "                  ,count(*) AS observed\n",
    "            FROM public.model_inputs\n",
    "            GROUP BY 1,2\n",
    "        )\n",
    "        SELECT '{feature_name}' AS feature_name\n",
    "              ,'{response}' AS response\n",
    "              ,(madlib.chi2_gof_test(observed, expected, deg_freedom)).*\n",
    "        FROM (\n",
    "            SELECT observed\n",
    "                  ,sum(observed) OVER (PARTITION BY {feature_name})::DOUBLE PRECISION\n",
    "                       * sum(observed) OVER (PARTITION BY {response}) AS expected\n",
    "            FROM freq\n",
    "        ) l, (\n",
    "            SELECT (count(distinct {feature_name}) - 1) * (count(distinct {response}) - 1) AS deg_freedom\n",
    "            FROM freq\n",
    "        ) r;\n",
    "    \"\"\".format(feature_name=feature_name, response=response)\n",
    "    cur.execute(query)\n",
    "\n",
    "    colnames = [desc[0] for desc in cur.description]\n",
    "    return pd.DataFrame(cur.fetchall(), columns=colnames)\n",
    "\n",
    "def chi2_gof_test_multi(feature_list, response):\n",
    "    res = chi2_gof_test(feature_list[0], response)\n",
    "    for i in range(1,len(feature_list)):\n",
    "        res = res.append(chi2_gof_test(feature_list[i], response))\n",
    "        \n",
    "    return res\n",
    "\n",
    "chi2_results = chi2_gof_test_multi(catFeatureNames, 'approval')\n",
    "chi2_results.sort_values('phi', inplace=True)\n",
    "ipd.display(chi2_results)\n",
    "bar_plot(chi2_results, \"Chi-Squared Testing\",\"feature_name\",\"Feature Name\",\"phi\",\"Test Statistic\", \"#4378E2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<a id=\"fe_corr\"></a>\n",
    "#### Correlation Testing\n",
    "\n",
    "https://madlib.apache.org/docs/latest/group__grp__correlation.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# calc correlations\n",
    "query = \"\"\"\n",
    "    DROP TABLE IF EXISTS public.feature_correlations, public.feature_correlations_summary;\n",
    "    SELECT madlib.correlation( \n",
    "        'public.training_data',\n",
    "        'public.feature_correlations',\n",
    "        '{}'\n",
    "    );\n",
    "    SELECT * \n",
    "    FROM public.feature_correlations\n",
    "    ORDER BY column_position;\n",
    "\"\"\".format(\",\".join(contFeatureNames))\n",
    "corr = query_gpdb(query)\n",
    "\n",
    "corr.drop('column_position', 'columns', inplace=True)\n",
    "corr.set_index('variable', True, False, True)\n",
    "corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "DROP TABLE IF EXISTS public.feature_correlations, public.feature_correlations_summary;\n",
    "SELECT madlib.correlation( \n",
    "        'public.training_data',\n",
    "        'public.feature_correlations'\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = %sql SELECT * FROM public.feature_correlations ORDER BY column_position;\n",
    "corr = corr.DataFrame()\n",
    "corr.drop('column_position', 'columns', inplace=True)\n",
    "corr.set_index('variable', True, False, True)\n",
    "corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Generate a mask for the upper triangle\n",
    "mask = np.zeros_like(corr, dtype=np.bool)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "\n",
    "# Set up the matplotlib figure\n",
    "#f, ax = plt.subplots(figsize=(11, 9))\n",
    "f, ax = plt.subplots(figsize=(13, 11))\n",
    "\n",
    "# Generate a custom diverging colormap\n",
    "cmap = sns.diverging_palette(220, 10, as_cmap=True)\n",
    "\n",
    "# Draw the heatmap with the mask and correct aspect ratio\n",
    "sns.heatmap(corr, mask=mask, cmap=cmap, vmax=.3, center=0,\n",
    "            square=True, linewidths=.5, cbar_kws={\"shrink\": .5}, annot=False);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<a id=\"fe_scatter\"></a>\n",
    "#### Scatter Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def sample_scatter(title, x, xLabel, y, yLabel, sampleSize):\n",
    "    \n",
    "    pylab.rcParams['figure.figsize'] = (8, 8)\n",
    "\n",
    "    # Grab sample\n",
    "    query = \"\"\"\n",
    "        SELECT count(*) AS n\n",
    "        FROM public.model_inputs;\n",
    "    \"\"\".format(\",\".join(contFeatureNames))\n",
    "    cur.execute(query)\n",
    "\n",
    "    colnames = [desc[0] for desc in cur.description]\n",
    "    n = pd.DataFrame(cur.fetchall(), columns=colnames)['n'][0]\n",
    "    limit = math.floor(n * sampleSize)\n",
    "    \n",
    "    query = \"\"\"\n",
    "        SELECT {} AS col1\n",
    "              ,{} AS col2\n",
    "        FROM public.model_inputs\n",
    "        LIMIT {};\n",
    "    \"\"\".format(x, y, limit)\n",
    "    cur.execute(query)\n",
    "\n",
    "    colnames = [desc[0] for desc in cur.description]\n",
    "    sample = pd.DataFrame(cur.fetchall(), columns=colnames)    \n",
    "    \n",
    "    # Generate scatterplot\n",
    "    if x == y:\n",
    "        sample\n",
    "    plt = sns.regplot(x=\"col1\", y=\"col2\", data=sample)\n",
    "    \n",
    "    # titles\n",
    "    plt.set_title(\"\\n\".join(tw.wrap(title,50)),fontsize=16)\n",
    "    plt.set_xlabel(xLabel,fontsize=16)\n",
    "    plt.set_ylabel(yLabel,fontsize=16)\n",
    "\n",
    "    # add 1000s commas\n",
    "    plt.get_yaxis().set_major_formatter(\n",
    "        matplotlib.ticker.FuncFormatter(lambda y, p: format(int(y), ',')))\n",
    "    plt.get_xaxis().set_major_formatter(\n",
    "        matplotlib.ticker.FuncFormatter(lambda y, p: format(int(y), ',')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "x = contFeatureNames[0]\n",
    "y = contFeatureNames[1]\n",
    "\n",
    "def reset():\n",
    "    ipd.clear_output()\n",
    "    printmd(\"-----\\n **Select Features:**\")\n",
    "    ipd.display(scatterDropdown1, scatterDropdown2)\n",
    "\n",
    "    sample_scatter(\"{} by {}\".format(x, y), x, x, y, y, 1)   \n",
    "    \n",
    "def os1(res):\n",
    "    global x\n",
    "    if res['type'] == 'change' and res['name'] == 'value':\n",
    "        contFeatureNames.append(x)\n",
    "        x = res['new']\n",
    "        contFeatureNames.remove(x)\n",
    "        reset()\n",
    "\n",
    "def os2(res):\n",
    "    global y\n",
    "    if res['type'] == 'change' and res['name'] == 'value':\n",
    "        y = res['new']\n",
    "        reset()\n",
    "                   \n",
    "scatterDropdown1 = widgets.Dropdown(\n",
    "    options=contFeatureNames,\n",
    "    value=x,\n",
    "    description='x:',\n",
    "    disabled=False,\n",
    ")\n",
    "\n",
    "scatterDropdown2 = widgets.Dropdown(\n",
    "    options=contFeatureNames,\n",
    "    value=y,\n",
    "    description='y:',\n",
    "    disabled=False,\n",
    ")\n",
    "\n",
    "scatterDropdown1.observe(os1)\n",
    "scatterDropdown2.observe(os2)\n",
    "\n",
    "reset()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<a id=\"tag\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### (OLD NOTEBOOK) Training & Validation Sample Split\n",
    "<a id=\"train_vali_split\"></a>\n",
    "https://madlib.apache.org/docs/latest/group__grp__train__test__split.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# split training and validation set\n",
    "# we are careful not to include the same customer in both sets\n",
    "query = \"\"\"\n",
    "    DROP TABLE IF EXISTS public.model\n",
    "                        ,public.model_train\n",
    "                        ,public.model_test;\n",
    "                        \n",
    "    SELECT madlib.train_test_split(\n",
    "        'public.model_inputs',\n",
    "        'public.model',\n",
    "        0.7,\n",
    "        NULL,\n",
    "        NULL,\n",
    "        '*',\n",
    "        FALSE,\n",
    "        TRUE\n",
    "    )\n",
    "\"\"\"\n",
    "cur.execute(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "    SELECT *\n",
    "    FROM public.model_train\n",
    "    LIMIT 5\n",
    "\"\"\"\n",
    "df = query_gpdb(query)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest (MADlib)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run #1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql SET search_path=network_anomaly_run1,madlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "DROP TABLE IF EXISTS training_data_sample1;\n",
    "SELECT madlib.balance_sample(\n",
    "                              'public.training_data',             -- Source table\n",
    "                              'training_data_sample1',      -- Output table\n",
    "                              'y',           -- Class column\n",
    "                              'uniform',           -- Uniform sample\n",
    "                               2300);                -- Desired output table size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql ALTER TABLE training_data_sample1 DROP COLUMN __madlib_id__;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run #2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql SET search_path=network_anomaly_run2,madlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql \n",
    "DROP TABLE IF EXISTS y;\n",
    "CREATE TABLE y AS SELECT y, (COUNT(*)>=1000) AS is_top FROM public.training_data GROUP BY y;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql DROP TABLE IF EXISTS training_data_top;\n",
    "CREATE TABLE training_data_top AS\n",
    "    SELECT *\n",
    "FROM public.training_data JOIN y USING(y) WHERE is_top=TRUE;\n",
    "SELECT COUNT(*) FROM training_data_top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql DROP TABLE IF EXISTS training_data_bottom;\n",
    "CREATE TABLE training_data_bottom AS\n",
    "    SELECT *\n",
    "FROM public.training_data JOIN y USING(y) WHERE is_top=FALSE;\n",
    "SELECT COUNT(*) FROM training_data_bottom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "DROP TABLE IF EXISTS training_data_top_sample2;\n",
    "SELECT madlib.balance_sample(\n",
    "                              'training_data_top',              -- Source table\n",
    "                              'training_data_top_sample2',      -- Output table\n",
    "                              'y',                 -- Class column\n",
    "                              'uniform',           -- Uniform sample\n",
    "                               9000);              -- Desired output table size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql SELECT y, COUNT(*) FROM training_data_top_sample2 GROUP BY y;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "DROP TABLE IF EXISTS training_data_bottom_sample2;\n",
    "SELECT madlib.balance_sample(\n",
    "                              'training_data_bottom',              -- Source table\n",
    "                              'training_data_bottom_sample2',      -- Output table\n",
    "                              'y',                 -- Class column\n",
    "                              'uniform',           -- Uniform sample\n",
    "                               1400);              -- Desired output table size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql SELECT y, COUNT(*) FROM training_data_bottom_sample2 GROUP BY y;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "    DROP TABLE IF EXISTS training_data_balanced2;\n",
    "    CREATE TABLE training_data_balanced2 AS\n",
    "    SELECT * FROM training_data_top_sample2 UNION SELECT * FROM training_data_bottom_sample2;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql SELECT y,count(*) FROM training_data_balanced2 GROUP BY y ORDER BY 2;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql ALTER TABLE training_data_balanced2 DROP COLUMN is_top;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "DROP TABLE IF EXISTS balanced2_train, balanced2_test;\n",
    "SELECT madlib.train_test_split(\n",
    "                                'training_data_balanced2',    -- Source table\n",
    "                                'balanced2',            -- Output table\n",
    "                                0.8,       -- Sample proportion\n",
    "                                NULL,       -- Sample proportion\n",
    "                                NULL,       -- Strata definition\n",
    "                                NULL,       -- Columns to output\n",
    "                                FALSE,     -- Sample without replacement\n",
    "                                TRUE);    -- Do not separate output tables\n",
    "SELECT y,COUNT(*) FROM balanced2_train GROUP BY y;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"#tag\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql SELECT y,COUNT(*) FROM balanced2_test GROUP BY y;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run #3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql SET search_path=network_anomaly_run3,madlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "DROP TABLE IF EXISTS training_data_sample3;\n",
    "SELECT madlib.balance_sample(\n",
    "                              'public.training_data',             -- Source table\n",
    "                              'training_data_sample3',      -- Output table\n",
    "                              'y',           -- Class column\n",
    "                              'uniform',           -- Uniform sample\n",
    "                               230000);                -- Desired output table size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql ALTER TABLE training_data_sample3 DROP COLUMN __madlib_id__;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "DROP TABLE IF EXISTS balanced3_train, balanced3_test;\n",
    "SELECT madlib.train_test_split(\n",
    "                                'training_data_sample3',    -- Source table\n",
    "                                'balanced3',            -- Output table\n",
    "                                0.8,       -- Sample proportion\n",
    "                                NULL,       -- Sample proportion\n",
    "                                NULL,       -- Strata definition\n",
    "                                NULL,       -- Columns to output\n",
    "                                FALSE,     -- Sample without replacement\n",
    "                                TRUE);    -- Separate output tables\n",
    "SELECT y,COUNT(*) FROM balanced3_train GROUP BY y;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "SELECT y,COUNT(*) FROM balanced3_test GROUP BY y;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run #4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "DROP TABLE IF EXISTS training_data_sample4;\n",
    "SELECT madlib.balance_sample(\n",
    "                              'public.training_data',             -- Source table\n",
    "                              'training_data_sample4',      -- Output table\n",
    "                              'y',           -- Class column\n",
    "                               $$\n",
    "                               class19=10, class12=10, class13=10, \n",
    "                               class09=20, class03=20, class08=20, class16=20, class05=20, \n",
    "                               class22=100, class07=100, class02=100, class04=100,\n",
    "                               class14=1000, \n",
    "                               class20=5000, class21=5000, class01=5000, class11=5000, \n",
    "                               class15=20000, class06=20000, class17=20000,\n",
    "                               normal=100000, class10=100000, class18=100000\n",
    "                               $$);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql ALTER TABLE training_data_sample4 DROP COLUMN __madlib_id__;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "DROP TABLE IF EXISTS balanced4_train, balanced4_test;\n",
    "SELECT madlib.train_test_split(\n",
    "                                'training_data_sample4',    -- Source table\n",
    "                                'balanced4',            -- Output table\n",
    "                                0.8,       -- Sample proportion\n",
    "                                NULL,       -- Sample proportion\n",
    "                                NULL,       -- Strata definition\n",
    "                                NULL,       -- Columns to output\n",
    "                                FALSE,     -- Sample without replacement\n",
    "                                TRUE);    -- Separate output tables\n",
    "SELECT y,COUNT(*) FROM balanced4_train GROUP BY y;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "SELECT y,COUNT(*) FROM balanced4_test GROUP BY y;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model\n",
    "<a id=\"rf_train_model\"></a>\n",
    "https://madlib.apache.org/docs/latest/group__grp__random__forest.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql ALTER TABLE balanced2_train DROP COLUMN __madlib_id__;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql ALTER TABLE balanced2_test DROP COLUMN __madlib_id__;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "DROP TABLE IF EXISTS rf_model4, rf_model4_summary, rf_model4_group;\n",
    "SELECT madlib.forest_train(\n",
    "            'training_data_sample4',  -- source table\n",
    "            'rf_model4',              -- output table\n",
    "            'id',                     -- unique row id\n",
    "            'y',                      -- dependent var\n",
    "            '*',                      -- indep var\n",
    "            null,                     -- cols to exclude\n",
    "            null,                     -- grouping\n",
    "            10::integer,              -- num trees\n",
    "            5::integer,               -- num random features\n",
    "            true::boolean,            -- importance\n",
    "            5::integer,               -- num permutations\n",
    "            10::integer,              -- max tree depth\n",
    "            3::integer,               -- min split\n",
    "            1::integer,               -- min bucket\n",
    "            10::integer,               -- num splits\n",
    "            NULL,                     -- null handling\n",
    "            TRUE                      -- verbose\n",
    "        );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "    SELECT gid, sample_id\n",
    "    FROM rf_model4;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"rf_variable_importance\"></a>\n",
    "#### Variable Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"SET search_path=public, madlib;\n",
    "    SELECT unnest(string_to_array(independent_varnames,',')) AS feature_name\n",
    "          ,unnest(impurity_var_importance) AS impurity_feature_importance\n",
    "          ,unnest(oob_var_importance) AS oob_feature_importance\n",
    "    FROM rf_model4_group l\n",
    "        ,rf_model4_summary r\n",
    "    ORDER BY 2 DESC\n",
    "\"\"\"\n",
    "\n",
    "df = query_gpdb(query)\n",
    "ipd.display(df.head(10))\n",
    "bar_plot(df,\"Feature Importance\",\"feature_name\",'Feature Name',\"impurity_feature_importance\",\"Feature Importance\", \"#4378E2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bar_plot(df,\"Feature Importance\",\"feature_name\",'Feature Name',\"oob_feature_importance\",\"Feature Importance\", \"#4378E2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "DROP TABLE IF EXISTS feature_importance;\n",
    "SELECT get_var_importance('rf_model4', 'feature_importance');\n",
    "SELECT * FROM feature_importance ORDER BY impurity_var_importance DESC;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"rf_score_out_of_sample\"></a>\n",
    "#### Score Validation/Training Data\n",
    "\n",
    "https://madlib.apache.org/docs/latest/group__grp__random__forest.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate validation dataset\n",
    "query = \"\"\"\n",
    "    DROP TABLE IF EXISTS rf_model4_scored;\n",
    "    SELECT madlib.forest_predict('rf_model4',\n",
    "                                 'balanced4_test',\n",
    "                                 'rf_model4_scored',\n",
    "                                 'response');\n",
    "                \n",
    "    DROP TABLE IF EXISTS rf_model4_scored_tmp;\n",
    "    CREATE TABLE rf_model4_scored_tmp AS\n",
    "    SELECT *\n",
    "    FROM rf_model4_scored\n",
    "    JOIN balanced4_test\n",
    "    USING (id);\n",
    "    DROP TABLE rf_model4_scored;\n",
    "    ALTER TABLE rf_model4_scored_tmp RENAME TO rf_model4_scored;\n",
    "    SELECT * FROM rf_model4_scored LIMIT 10;\n",
    "    \n",
    "\"\"\"\n",
    "cur.execute(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate training dataset\n",
    "query = \"\"\"\n",
    "    DROP TABLE IF EXISTS rf_model4_scored;\n",
    "    SELECT madlib.forest_predict('rf_model4',\n",
    "                                 'balanced4_train',\n",
    "                                 'rf_model4_scored',\n",
    "                                 'response');\n",
    "                \n",
    "    DROP TABLE IF EXISTS rf_model4_scored_tmp;\n",
    "    CREATE TABLE rf_model4_scored_tmp AS\n",
    "    SELECT *\n",
    "    FROM rf_model4_scored\n",
    "    JOIN balanced4_train\n",
    "    USING (id);\n",
    "    DROP TABLE rf_model4_scored;\n",
    "    ALTER TABLE rf_model4_scored_tmp RENAME TO rf_model4_scored;\n",
    "    SELECT * FROM rf_model4_scored LIMIT 10;\n",
    "    \n",
    "\"\"\"\n",
    "cur.execute(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on entire 4.9-million \"training\" dataset\n",
    "query = \"\"\"\n",
    "    DROP TABLE IF EXISTS rf_model1_scored;\n",
    "    SELECT madlib.forest_predict('rf_model1',\n",
    "                                 'public.training_data',\n",
    "                                 'rf_model1_scored',\n",
    "                                 'response');\n",
    "                \n",
    "    DROP TABLE IF EXISTS rf_model1_scored_tmp;\n",
    "    CREATE TABLE rf_model1_scored_tmp AS\n",
    "    SELECT *\n",
    "    FROM rf_model1_scored\n",
    "    JOIN public.training_data\n",
    "    USING (id);\n",
    "    DROP TABLE rf_model1_scored;\n",
    "    ALTER TABLE rf_model1_scored_tmp RENAME TO rf_model1_scored;\n",
    "    SELECT * FROM rf_model1_scored LIMIT 10;\n",
    "    \n",
    "\"\"\"\n",
    "cur.execute(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on 311K \"eval\" dataset\n",
    "query = \"\"\"\n",
    "    DROP TABLE IF EXISTS rf_model1_scored;\n",
    "    SELECT madlib.forest_predict('rf_model1',\n",
    "                                 'public.eval_data',\n",
    "                                 'rf_model1_scored',\n",
    "                                 'response');\n",
    "                \n",
    "    DROP TABLE IF EXISTS rf_model1_scored_tmp;\n",
    "    CREATE TABLE rf_model1_scored_tmp AS\n",
    "    SELECT *\n",
    "    FROM rf_model1_scored\n",
    "    JOIN public.eval_data\n",
    "    USING (id);\n",
    "    DROP TABLE rf_model1_scored;\n",
    "    ALTER TABLE rf_model1_scored_tmp RENAME TO rf_model1_scored;\n",
    "    SELECT * FROM rf_model1_scored LIMIT 10;\n",
    "    \n",
    "\"\"\"\n",
    "cur.execute(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "select * from rf_model2_scored order by id limit 10;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql \n",
    "SET search_path=network_anomaly_run2, madlib;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "DROP TABLE IF EXISTS confusion;\n",
    "SELECT madlib.confusion_matrix( 'rf_model4_scored', 'confusion', 'estimated_y', 'y');\n",
    "SELECT * FROM confusion ORDER BY \"class\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql DROP TABLE IF EXISTS accuracy_by_class;\n",
    "CREATE TABLE accuracy_by_class AS\n",
    "    SELECT y,correct, total,correct::FLOAT/total as accuracy\n",
    "FROM (SELECT y, COUNT(*) AS correct FROM rf_model4_scored WHERE y=estimated_y GROUP BY y) c JOIN\n",
    "     (SELECT y,count(*) AS total FROM rf_model4_scored GROUP BY y) t USING(y);\n",
    "SELECT * FROM accuracy_by_class ORDER BY y;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql SELECT AVG(accuracy) AS balanced_accuracy FROM accuracy_by_class;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build histogram by class if don't have label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "select estimated_y, count(*) from rf_model3_scored group by estimated_y order by estimated_y;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Rest of OLD NOTEBOOK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<a id=\"rf_auc\"></a>\n",
    "#### Area Under ROC Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# auc\n",
    "query = \"\"\"\n",
    "    DROP TABLE IF EXISTS public.model_test_scored_auc;\n",
    "    SELECT madlib.area_under_roc(\n",
    "        'public.model_test_scored'\n",
    "       ,'public.model_test_scored_auc'\n",
    "       ,'estimated_prob_1'\n",
    "       ,'approval'\n",
    "    )\n",
    "\"\"\"\n",
    "cur.execute(query)\n",
    "\n",
    "query = \"\"\"\n",
    "    SELECT * \n",
    "    FROM public.model_test_scored_auc;\n",
    "\"\"\"\n",
    "auc = query_gpdb(query)['area_under_roc'][0]\n",
    "\n",
    "message = \"\"\"-----\\n **AUC =** {:0.5f}\"\"\".format(auc)\n",
    "printmd(message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<a id=\"rf_roc\"></a>\n",
    "#### Receiver Operating Characteristic Graph (ROC Curve)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# roc\n",
    "query = \"\"\"\n",
    "    DROP TABLE IF EXISTS public.model_test_scored_roc;\n",
    "    SELECT madlib.binary_classifier( \n",
    "        'public.model_test_scored'\n",
    "       ,'public.model_test_scored_roc'\n",
    "       ,'estimated_prob_1'\n",
    "       ,'approval'\n",
    "    );\n",
    "\"\"\"\n",
    "cur.execute(query)\n",
    "\n",
    "query = \"\"\"\n",
    "    SELECT threshold\n",
    "          ,fpr\n",
    "          ,tpr\n",
    "    FROM public.model_test_scored_roc\n",
    "    ORDER BY 1\n",
    "\"\"\"\n",
    "df = query_gpdb(query)\n",
    "\n",
    "# roc curve\n",
    "pylab.rcParams['figure.figsize'] = (8, 8)\n",
    "\n",
    "plt.figure()\n",
    "lw = 2\n",
    "plt.plot(df['fpr'], df['tpr'], color='darkgreen', lw=lw, label='AUC {:0.2f}'.format(auc))\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<a id=\"rf_confusion_matrix\"></a>\n",
    "#### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# confusion matrix (inclusive)\n",
    "cutoff = 0.5\n",
    "\n",
    "query = \"\"\"\n",
    "        SELECT approval AS obs\n",
    "              ,CASE WHEN estimated_prob_1 >= {} THEN 1 ELSE 0 END AS pred\n",
    "              ,count(*) AS num\n",
    "        FROM public.model_test_scored\n",
    "        GROUP BY 1,2\n",
    "        ORDER BY 1,2\n",
    "    \"\"\".format(cutoff)\n",
    "\n",
    "query_gpdb(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<a id=\"rf_model_storage\"></a>\n",
    "#### Model Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "        DROP TABLE IF EXISTS public.my_models;\n",
    "        CREATE TABLE public.my_models (\n",
    "            gid integer[]\n",
    "           ,sample_id integer[]\n",
    "           ,tree madlib.bytea8[]\n",
    "           ,created timestamp\n",
    "           ,team text\n",
    "           ,owner text\n",
    "           ,description text\n",
    "           ,model_type text\n",
    "           ,model_params text\n",
    "           ,current boolean\n",
    "           ,model_id serial\n",
    "        );\n",
    "        \n",
    "        INSERT INTO public.my_models (\n",
    "            SELECT array_agg(gid) AS gid\n",
    "                  ,array_agg(sample_id) AS sample_id\n",
    "                  ,array_agg(tree) AS tree\n",
    "                  ,now() AS created\n",
    "                  ,'Pivotal Data Science Atlanta' AS team\n",
    "                  ,'Jarrod Vawdrey' AS owner\n",
    "                  ,'This is an example credit scoring model' AS description\n",
    "                  ,'MADlib random forest' AS model_type\n",
    "                  ,'{num_trees= ,num_random_features= ,importance= ,num_permutations= ,max_tree_depth= ,min_split= ,min_bucket= ,num_splits= }' AS model_params\n",
    "                  ,True AS current\n",
    "            FROM public.rf_model_output   \n",
    "        );\n",
    "        \n",
    "        SELECT gid\n",
    "              ,sample_id\n",
    "              ,created\n",
    "              ,team\n",
    "              ,owner\n",
    "              ,description\n",
    "              ,model_type\n",
    "              ,model_params\n",
    "              ,current\n",
    "        FROM public.my_models\n",
    "    \"\"\"\n",
    "\n",
    "query_gpdb(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Model Scoring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<a id=\"model_scoring_Example\"></a>\n",
    "#### Model Scoring Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "<a id=\"rf_train_model\"></a>\n",
    "featureNames = ['a2', 'a3', 'a8', 'a11', 'a14', 'a15', 'a1_a', 'a4_l', 'a4_u', 'a5_g', 'a5_gg', 'a6_aa', 'a6_c', 'a6_cc', 'a6_d', 'a6_e', 'a6_ff', 'a6_i', 'a6_j', 'a6_k', 'a6_m', 'a6_q', 'a6_r', 'a6_w', 'a7_bb', 'a7_dd', 'a7_ff', 'a7_h', 'a7_j', 'a7_n', 'a7_o', 'a7_v', 'a9_true', 'a10_true', 'a12_true', 'a13_g', 'a13_p']\n",
    "    \n",
    "\n",
    "def add_continuous_slider(n, default):\n",
    "    tstr = \"target_column == '{}'\".format(n)\n",
    "    minValue = math.floor(data_summary.query(tstr)['min'])\n",
    "    minValueOrZero = min(0,float(minValue))\n",
    "    maxValue = math.ceil(data_summary.query(tstr)['max'])\n",
    "    return widgets.FloatSlider(\n",
    "        value=default,\n",
    "        min=minValueOrZero,\n",
    "        max=maxValue,\n",
    "        step=0.1,\n",
    "        description=\"\",\n",
    "        disabled=False,\n",
    "        continuous_update=False,\n",
    "        orientation='horizontal',\n",
    "        readout=True,\n",
    "        readout_format='.1f',\n",
    "    )\n",
    "\n",
    "def add_drop_down(n, default):\n",
    "    \n",
    "    query = \"\"\"\n",
    "        SELECT {} AS col\n",
    "        FROM public.credit_application_data\n",
    "        GROUP BY 1\n",
    "        ORDER BY 1\n",
    "    \"\"\".format(n)\n",
    "    values = query_gpdb(query)['col']\n",
    "\n",
    "    return widgets.Dropdown(\n",
    "        options=values,\n",
    "        value=default,\n",
    "        description='',\n",
    "        disabled=False,\n",
    "    )\n",
    "\n",
    "def add_widgets():\n",
    "    \n",
    "    message = \"### Loan Application \\n ------\"\n",
    "    printmd(message)\n",
    "    \n",
    "    myWidgets = []\n",
    "\n",
    "    myWidgets.append({'a1':add_drop_down('a1','a')})\n",
    "    myWidgets.append({'a2':add_continuous_slider('a2',35.43)})\n",
    "    myWidgets.append({'a3':add_continuous_slider('a3',12.0)})\n",
    "    myWidgets.append({'a4':add_drop_down('a4','u')})\n",
    "    myWidgets.append({'a5':add_drop_down('a5','g')})\n",
    "    myWidgets.append({'a6':add_drop_down('a6','q')})\n",
    "    myWidgets.append({'a7':add_drop_down('a7','h')})\n",
    "    myWidgets.append({'a8':add_continuous_slider('a8',14.0)})\n",
    "    myWidgets.append({'a9':add_drop_down('a9',True)})\n",
    "    myWidgets.append({'a10':add_drop_down('a10',True)})\n",
    "    myWidgets.append({'a11':add_continuous_slider('a11',8.0)})\n",
    "    myWidgets.append({'a12':add_drop_down('a12',False)})\n",
    "    myWidgets.append({'a13':add_drop_down('a13','g')})\n",
    "    myWidgets.append({'a14':add_continuous_slider('a14',0.0)})\n",
    "    myWidgets.append({'a15':add_continuous_slider('a15',6590.0)})\n",
    "    \n",
    "    for widget in myWidgets:\n",
    "        n = widget.keys()[0]\n",
    "        printmd(\"**{}:**\".format(n))\n",
    "        ipd.display(widget[n])\n",
    "\n",
    "    message = \"------\"\n",
    "    printmd(message)\n",
    "    \n",
    "    return myWidgets\n",
    "\n",
    "    \n",
    "def create_model_input(myWidgets):\n",
    "\n",
    "    checks = {}\n",
    "    conts = []\n",
    "    f = []\n",
    "    \n",
    "    for i in range(0,len(featureNames)):\n",
    "        f.append(0.0)\n",
    "    \n",
    "    for feature in featureNames:\n",
    "        if \"_\" in feature:\n",
    "            key = feature[0:feature.find(\"_\")]\n",
    "            val = feature[feature.find(\"_\")+1:len(feature)]\n",
    "            if key in checks:\n",
    "                checks[key].append(val)\n",
    "            else:\n",
    "                checks[key] = [val]\n",
    "        else:\n",
    "            conts.append(feature)\n",
    "            \n",
    "    for widget in myWidgets:\n",
    "        n = widget.keys()[0]\n",
    "        val = widget[n].value\n",
    "\n",
    "        # lower case boolean strings\n",
    "        if isinstance(val,np.bool_):\n",
    "            val = str(val).lower()\n",
    "\n",
    "        if n in checks:\n",
    "            checkFlag = False\n",
    "            for c in checks[n]:\n",
    "                if c == val:\n",
    "                    checkFlag = True\n",
    "                    pos = featureNames.index(\"{}_{}\".format(n,val))\n",
    "                    f[pos] = 1.0   \n",
    "                    \n",
    "            # make all associated values 0\n",
    "            if checkFlag == False:\n",
    "                for feature in featureNames:\n",
    "                    if \"_\" in feature and feature[0:feature.find(\"_\")+1] == n:\n",
    "                        pos = featureNames.index(feature)\n",
    "                        f[pos] = 0.0   \n",
    "        elif n in conts:\n",
    "            pos = featureNames.index(n)\n",
    "            f[pos] = val\n",
    "\n",
    "    return f\n",
    "        \n",
    "def rf_score(modelInputs):\n",
    "    \n",
    "    print(modelInputs)\n",
    "    print(featureNames)\n",
    "    \n",
    "    ddlString = \"_id integer\"\n",
    "    for f in featureNames:\n",
    "        ddlString = ddlString + \",{} float\".format(f)\n",
    "\n",
    "    query = \"\"\"\n",
    "        DROP TABLE IF EXISTS public.prod_example_data, public.prod_example_score;\n",
    "        CREATE TABLE public.prod_example_data ({});\n",
    "        INSERT INTO public.prod_example_data VALUES ({});\n",
    "        DROP TABLE IF EXISTS public.model_test_scored_tmp;\n",
    "        SELECT madlib.forest_predict('public.rf_model_output',\n",
    "                                     'public.prod_example_data',\n",
    "                                     'public.prod_example_score',\n",
    "                                     'prob');\n",
    "        SELECT * FROM public.prod_example_score;\n",
    "    \"\"\".format(ddlString, \",\".join(str(x) for x in modelInputs))\n",
    "\n",
    "    score = float(query_gpdb(query)['estimated_prob_1'])\n",
    "    \n",
    "    message = \"High\"\n",
    "    if score <= 0.5:\n",
    "        message = \"Low\"\n",
    "    elif score <= 0.75:\n",
    "        message = \"Average\"\n",
    "    \n",
    "    return (score, message)\n",
    "    \n",
    "def on_appbutton_click(b):\n",
    "    \n",
    "    ipd.clear_output()\n",
    "    \n",
    "    message = \"### Loan Approval Results \\n------\\n\"\n",
    "    printmd(message)\n",
    "    \n",
    "    modelInput = create_model_input(myWidgets)\n",
    "    \n",
    "    s, m = rf_score(modelInput)\n",
    "    \n",
    "    message = \"**Approval Score:** {}\".format(s)\n",
    "    printmd(message)\n",
    "    \n",
    "    message = \"*Your chances of being approved are '{}'*\".format(m)\n",
    "    printmd(message)\n",
    "    \n",
    "    cleanModelInputs = \"\"\n",
    "    for i in range(0,len(featureNames)):\n",
    "        cleanModelInputs = cleanModelInputs + \"{} = {}\\n\\n\".format(featureNames[i],modelInput[i])\n",
    "\n",
    "    message = \"**Model Inputs:** \\n\\n{}\".format(cleanModelInputs)\n",
    "    printmd(message)\n",
    "    \n",
    "    printmd(\"\\n------\")\n",
    "    \n",
    "myWidgets = add_widgets()\n",
    "appbutton = widgets.Button(description=\"Calculate Approval\")\n",
    "ipd.display(appbutton)\n",
    "appbutton.on_click(on_appbutton_click)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
